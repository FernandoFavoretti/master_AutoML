{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-14 14:22:01,767\tWARNING worker.py:1373 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2020-09-14 14:22:01,769\tINFO node.py:498 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-09-14_14-22-01_768757_46885/logs.\n",
      "2020-09-14 14:22:01,881\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:62539 to respond...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not monitoring node memory since `psutil` is not installed. Install this with `pip install psutil` (or ray[debug]) to enable debugging of memory-related crashes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-14 14:22:02,006\tINFO services.py:409 -- Waiting for redis server at 127.0.0.1:62876 to respond...\n",
      "2020-09-14 14:22:02,009\tINFO services.py:809 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2020-09-14 14:22:02,027\tINFO node.py:512 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2020-09-14_14-22-01_768757_46885/logs.\n",
      "2020-09-14 14:22:02,037\tWARNING services.py:1301 -- Warning: Capping object memory store to 20.0GB. To increase this further, specify `object_store_memory` when calling ray.init() or ray start.\n",
      "2020-09-14 14:22:02,055\tINFO services.py:1475 -- Starting the Plasma object store with 20.0 GB memory using /dev/shm.\n",
      "2020-09-14 14:22:02,071\tWARNING services.py:912 -- Failed to start the reporter. The reporter requires 'pip install psutil'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.96.22.5',\n",
       " 'redis_address': '10.96.22.5:62539',\n",
       " 'object_store_address': '/tmp/ray/session_2020-09-14_14-22-01_768757_46885/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-09-14_14-22-01_768757_46885/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-09-14_14-22-01_768757_46885'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import operator\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize \n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from fangorn.files_prep import get_data, data_to_pandas\n",
    "from fangorn.preprocessing import splitting, feature_selection\n",
    "from fangorn.training import classifiers\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "import pymit\n",
    "\n",
    "import ray\n",
    "ray.init(num_cpus=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML_CHALLENGE files ready!\n"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "all_datasets = get_data.get_all_data(only='ml_challenge')\n",
    "this_dataset = 'madeline'\n",
    "\n",
    "# configure dataset\n",
    "X_all, y_all = data_to_pandas.read_prepare_data(this_dataset)\n",
    "# X_all = feature_selection.extra_trees_feature_selection(X_all, y_all)\n",
    "dataset_split_dict = splitting.simple_train_test_val_split(X_all, y_all)\n",
    "\n",
    "X_train = dataset_split_dict['train']['X']\n",
    "y_train = dataset_split_dict['train']['y']\n",
    "X_test = dataset_split_dict['test']['X']\n",
    "y_test = dataset_split_dict['test']['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_discretize(X_train, X_test, max_gran=10):\n",
    "    \"\"\"\n",
    "    multi-granularity discretization\n",
    "    method. The basic idea is simple: instead of using a fine-tuned\n",
    "    granularity, we discretize each numerical feature into several, rather\n",
    "    than only one, categorical features, each with a different granularity.\n",
    "    \n",
    "    min granularity = 3\n",
    "    \n",
    "    Sometimes de edge values did not permit to execute correct discretization\n",
    "    if this happens the step is not executed\n",
    "    \"\"\"\n",
    "    \n",
    "    # separa dados numericos que precisam de binarizacao\n",
    "    is_numeric = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numeric_features = X_train.select_dtypes(include=is_numeric)\n",
    "    discrete_features = []\n",
    "    print(f\"Discretizing {len(numeric_features.columns)} features...\")\n",
    "    feat_count = 0\n",
    "    for feat in numeric_features:\n",
    "        if feat_count % 50 == 0:\n",
    "            print(f\" Working in {feat}\")\n",
    "        X_train_np = X_train[[feat]].to_numpy()\n",
    "        X_test_np = X_test[[feat]].to_numpy()\n",
    "        for gran in range(3, max_gran+1):\n",
    "            try:\n",
    "                D_train = np.zeros([X_train.shape[0], 1])\n",
    "                D_test = np.zeros([X_test.shape[0], 1])\n",
    "                # calc numpy histogram and apply to features\n",
    "                hist, bin_edges = np.histogram(X_train_np[:, 0], bins=gran)\n",
    "                D_train[:, 0] = np.digitize(X_train_np[:,0], bin_edges, right=False)\n",
    "                D_test[:, 0] = np.digitize(X_test_np[:,0], bin_edges, right=False)\n",
    "\n",
    "                # apply back to pandas\n",
    "                X_train[f\"{feat}_{gran}\"] = D_train\n",
    "                X_test[f\"{feat}_{gran}\"] = D_test\n",
    "            except:\n",
    "                print(f\"Not possible to correct work on cut {feat} > {gran}\")\n",
    "                break\n",
    "        \n",
    "        feat_count += 1\n",
    "        X_train = X_train.drop(feat, axis=1)\n",
    "        X_test = X_test.drop(feat, axis=1)\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing 259 features...\n",
      " Working in 0\n",
      " Working in 50\n",
      " Working in 100\n",
      " Working in 150\n",
      " Working in 200\n",
      " Working in 250\n"
     ]
    }
   ],
   "source": [
    "X_train_discrete, X_test_discrete = numpy_discretize(X_train.copy(), X_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjmi_selector(X, y, bins, max_features):\n",
    "    \n",
    "    X = X.to_numpy()\n",
    "    Y = y.to_numpy().ravel()\n",
    "\n",
    "    [tmp, features] = X.shape\n",
    "    D = np.zeros([tmp, features])\n",
    "\n",
    "    for i in range(features):\n",
    "        N, E = np.histogram(X[:,i], bins=bins)\n",
    "        D[:,i] = np.digitize(X[:,i], E, right=False)\n",
    "\n",
    "    selected_features = []\n",
    "    j_h = 0\n",
    "    hjmi = None\n",
    "    for i in range(0,max_features):\n",
    "        JMI = np.zeros([features], dtype=np.float)\n",
    "        for X_k in range(features):\n",
    "            if X_k in selected_features:\n",
    "                continue\n",
    "            jmi_1 = pymit.I(D[:,X_k], Y, bins=[bins,2])\n",
    "            jmi_2 = 0\n",
    "            for X_j in selected_features:\n",
    "                tmp1 = pymit.I(D[:,X_k], D[:,X_j], bins=[bins,bins])\n",
    "                tmp2 = pymit.I_cond(D[:,X_k], D[:,X_j], Y, bins=[bins,bins,2])\n",
    "                jmi_2 += tmp1 - tmp2\n",
    "            if len(selected_features) == 0:\n",
    "                JMI[X_k] += j_h + jmi_1\n",
    "            else:\n",
    "                JMI[X_k] += j_h + jmi_1 - jmi_2/len(selected_features)\n",
    "        \n",
    "        f = JMI.argmax()\n",
    "        j_h = JMI[f]\n",
    "        if (hjmi == None) or ((j_h - hjmi)/hjmi > 0.03):\n",
    "            r = 0\n",
    "            if hjmi != None:\n",
    "                r = ((j_h - hjmi)/hjmi) \n",
    "\n",
    "            hjmi = j_h\n",
    "            selected_features.append(f)\n",
    "            print(\"{:0>3d} {:>3d} {} - {}\".format(len(selected_features), f, j_h, r))\n",
    "        else:\n",
    "            return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 1902 0.05330720180283708 - 0\n",
      "002 687 0.16296850394591655 - 2.0571573527470948\n",
      "003 1479 0.24124708922089674 - 0.48032953226936453\n",
      "004 1535 0.3256292677095313 - 0.3497749082119306\n",
      "005 1303 0.40522943912027903 - 0.24445029763649154\n",
      "006 1903 0.47796290479927034 - 0.17948712175721954\n",
      "007 686 0.5569395618224394 - 0.16523595498762994\n",
      "008 423 0.6293285495907539 - 0.12997637936051878\n",
      "009 567 0.7025048318410445 - 0.11627675607260533\n",
      "010 1534 0.7778947246681412 - 0.10731583529400575\n",
      "011 684 0.8504461209951012 - 0.0932663431519107\n",
      "012 1901 0.9213396957940156 - 0.08336045405905593\n",
      "013 1471 0.9905527228656312 - 0.07512215894699666\n",
      "014 685 1.059457156533011 - 0.06956160139365622\n",
      "015 1533 1.1295119070972939 - 0.06612325013078524\n",
      "016 1087 1.1961512331162913 - 0.058998338663159657\n",
      "017 1487 1.2633314029794234 - 0.05616360875046699\n",
      "018 1900 1.3317803462321318 - 0.054181304360264776\n",
      "019 1863 1.3988168468659294 - 0.05033600384887572\n",
      "020 1470 1.4668449383850863 - 0.048632593803523944\n",
      "021 1531 1.5353419831691155 - 0.046696854583307607\n",
      "022 1486 1.6001822034593525 - 0.04223177702494631\n",
      "023 1899 1.6657466509877354 - 0.04097311380331723\n",
      "024 1478 1.7306037139430572 - 0.03893573066280132\n",
      "025 671 1.794030123338562 - 0.03664987477173053\n",
      "026 1532 1.8591799713271902 - 0.03631480159730478\n",
      "027 1302 1.922164677238381 - 0.03387768095749689\n",
      "028 1431 1.9856102513248528 - 0.033007356153077184\n",
      "029 1583 2.047134742003399 - 0.03098517981436455\n",
      "030 2022 2.108741928150347 - 0.03009434839968426\n"
     ]
    }
   ],
   "source": [
    "selected_features = hjmi_selector(X_train_discrete.copy(), y_train.copy(), bins=10, max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [1902, 687, 1479, 1535, 1303, 1903, 686, 423, 567, 1534, 684, 1901, 1471, 685, 1533, 1087, 1487, 1900, 1863, 1470, 1531, 1486, 1478, 671, 1523, 1302, 1431, 1583, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train = X_train_discrete[X_train_discrete.columns[selected_features]]\n",
    "filtered_test = X_test_discrete[X_test_discrete.columns[selected_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>237_9</th>\n",
       "      <th>85_10</th>\n",
       "      <th>184_10</th>\n",
       "      <th>191_10</th>\n",
       "      <th>162_10</th>\n",
       "      <th>237_10</th>\n",
       "      <th>85_9</th>\n",
       "      <th>52_10</th>\n",
       "      <th>70_10</th>\n",
       "      <th>191_9</th>\n",
       "      <th>...</th>\n",
       "      <th>183_9</th>\n",
       "      <th>191_6</th>\n",
       "      <th>185_9</th>\n",
       "      <th>184_9</th>\n",
       "      <th>83_10</th>\n",
       "      <th>190_6</th>\n",
       "      <th>162_9</th>\n",
       "      <th>178_10</th>\n",
       "      <th>197_10</th>\n",
       "      <th>252_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      237_9  85_10  184_10  191_10  162_10  237_10  85_9  52_10  70_10  191_9  \\\n",
       "2953    5.0    7.0     6.0     5.0     6.0     6.0   6.0    2.0    3.0    5.0   \n",
       "1560    8.0    4.0     7.0     8.0     4.0     9.0   4.0    6.0    4.0    7.0   \n",
       "2098    5.0    3.0     8.0     5.0     5.0     6.0   3.0    6.0    7.0    5.0   \n",
       "71      6.0    7.0     3.0     6.0     6.0     6.0   6.0    3.0    2.0    6.0   \n",
       "1636    6.0    7.0     5.0     6.0     7.0     6.0   7.0    6.0    3.0    6.0   \n",
       "...     ...    ...     ...     ...     ...     ...   ...    ...    ...    ...   \n",
       "2680    5.0    6.0     3.0     5.0     5.0     6.0   5.0    3.0    7.0    5.0   \n",
       "1854    7.0    3.0     4.0     8.0     2.0     8.0   3.0    3.0    7.0    7.0   \n",
       "217     6.0    4.0     8.0     6.0     4.0     6.0   3.0    4.0    6.0    6.0   \n",
       "2164    3.0    9.0     2.0     4.0     8.0     4.0   8.0    2.0    2.0    3.0   \n",
       "1697    6.0    4.0     7.0     7.0     4.0     7.0   4.0    3.0    3.0    7.0   \n",
       "\n",
       "      ...  183_9  191_6  185_9  184_9  83_10  190_6  162_9  178_10  197_10  \\\n",
       "2953  ...    4.0    3.0    5.0    5.0    2.0    5.0    6.0     3.0     5.0   \n",
       "1560  ...    6.0    5.0    4.0    6.0    4.0    4.0    4.0     3.0     5.0   \n",
       "2098  ...    7.0    3.0    4.0    7.0    7.0    2.0    4.0     4.0     8.0   \n",
       "71    ...    2.0    4.0    5.0    3.0    3.0    3.0    5.0     5.0     3.0   \n",
       "1636  ...    4.0    4.0    6.0    4.0    3.0    3.0    6.0     5.0     4.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...     ...     ...   \n",
       "2680  ...    2.0    3.0    4.0    3.0    7.0    2.0    4.0     7.0     5.0   \n",
       "1854  ...    3.0    5.0    2.0    4.0    7.0    3.0    2.0     5.0     4.0   \n",
       "217   ...    6.0    4.0    4.0    7.0    6.0    3.0    4.0     3.0     7.0   \n",
       "2164  ...    2.0    2.0    7.0    2.0    2.0    3.0    7.0     6.0     5.0   \n",
       "1697  ...    6.0    5.0    4.0    6.0    4.0    3.0    4.0     2.0     5.0   \n",
       "\n",
       "      252_9  \n",
       "2953    3.0  \n",
       "1560    3.0  \n",
       "2098    4.0  \n",
       "71      5.0  \n",
       "1636    5.0  \n",
       "...     ...  \n",
       "2680    7.0  \n",
       "1854    5.0  \n",
       "217     4.0  \n",
       "2164    6.0  \n",
       "1697    2.0  \n",
       "\n",
       "[2009 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(X_train, X_test):\n",
    "    ohe = OneHotEncoder(cols=X_train.columns).fit(X=X_train)\n",
    "    X_train = ohe.transform(X_train)\n",
    "    X_test = ohe.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "final_X_train, final_X_test = get_dummies(filtered_train.copy(), filtered_test.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_X_train.to_numpy()\n",
    "[tmp, features] = X.shape\n",
    "D = np.zeros([tmp, features])\n",
    "bins = 2\n",
    "for i in range(features):\n",
    "    N, E = np.histogram(X[:,i], bins=2)\n",
    "    D[:,i] = np.digitize(X[:,i], E, right=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 1. 1. ... 1. 1. 1.]\n",
      " [1. 3. 1. ... 1. 1. 1.]\n",
      " [3. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 3. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 3. ... 1. 1. 1.]]\n",
      "001 119 0.02300667735340972 - 0\n",
      "002 108 0.046401166807680166 - 1.0168565019147908\n",
      "003 203 0.07582262760604848 - 0.6340672621512304\n",
      "004 206 0.09993868406021007 - 0.31805883303677307\n",
      "005 177 0.12309585809961139 - 0.23171381789908113\n",
      "006 134 0.14465429754337655 - 0.1751353764179432\n",
      "007 264 0.16288740276715322 - 0.12604606661139273\n",
      "008 147 0.18035896831276102 - 0.10726161292278277\n",
      "009 100 0.1967068210705373 - 0.0906406424405102\n",
      "010 136 0.21474743753544126 - 0.0917132225853762\n",
      "011 283 0.2311906047157449 - 0.07656979458760671\n",
      "012 224 0.2473158362451812 - 0.06974864549215873\n",
      "013  13 0.26306459219651585 - 0.06367872025680486\n",
      "014 205 0.27934979934878085 - 0.061905735835781135\n",
      "015  37 0.2946753055981063 - 0.05486134690288734\n",
      "016 216 0.30947440758969924 - 0.05022172442157997\n",
      "017   5 0.3241142314048669 - 0.04730544257015627\n",
      "018 110 0.33893489463712967 - 0.04572666608319819\n",
      "019   4 0.353193548239471 - 0.04206900448420027\n",
      "020 101 0.36769743199150035 - 0.0410649736506383\n",
      "021  69 0.38174384634883607 - 0.03820101293952039\n",
      "022 176 0.395605950371139 - 0.0363125801630756\n",
      "023  11 0.40952906609048023 - 0.035194404195081554\n",
      "024 128 0.42319232429233583 - 0.033363341782526555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[119,\n",
       " 108,\n",
       " 203,\n",
       " 206,\n",
       " 177,\n",
       " 134,\n",
       " 264,\n",
       " 147,\n",
       " 100,\n",
       " 136,\n",
       " 283,\n",
       " 224,\n",
       " 13,\n",
       " 205,\n",
       " 37,\n",
       " 216,\n",
       " 5,\n",
       " 110,\n",
       " 4,\n",
       " 101,\n",
       " 69,\n",
       " 176,\n",
       " 11,\n",
       " 128]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hjmi_selector(final_X_train.copy(), y_train.copy(), bins=2, max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = [119,\n",
    " 108,\n",
    " 203,\n",
    " 206,\n",
    " 177,\n",
    " 134,\n",
    " 264,\n",
    " 147,\n",
    " 100,\n",
    " 136,\n",
    " 283,\n",
    " 224,\n",
    " 13,\n",
    " 205,\n",
    " 37,\n",
    " 216,\n",
    " 5,\n",
    " 110,\n",
    " 4,\n",
    " 101,\n",
    " 69,\n",
    " 176,\n",
    " 11,\n",
    " 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_final_train = final_X_train[final_X_train.columns[pp]]\n",
    "dummy_final_test = final_X_test[final_X_test.columns[pp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train = X_train_discrete.copy()\n",
    "filtered_test = X_test_discrete.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train['x'] = _treino[_treino.columns[23736]]\n",
    "final_X_test['x'] = final_X_test['191_9_4'] | final_X_test['191_6_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/basic/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.606687898089172"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(dummy_final_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, neigh.predict(dummy_final_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGLOSS: 0.659345746147491 - AUC: 0.6935060975609757\n"
     ]
    }
   ],
   "source": [
    "def run_initial_logit(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression(max_iter=3000).fit(X_train, y_train[y_train.columns[0]])\n",
    "    all_preds = clf.predict_proba(X_test)[:, 1]\n",
    "    logloss = metrics.log_loss(y_test[y_test.columns[0]], all_preds)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]], all_preds, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return clf, logloss, auc\n",
    "\n",
    "start_classifier, logloss, auc = run_initial_logit(final_X_train.copy(), y_train.copy(), final_X_test.copy(), y_test.copy())\n",
    "print(f\"LOGLOSS: {logloss} - AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(X_train, X_test):\n",
    "    ohe = OneHotEncoder(cols=X_train.columns).fit(X=X_train)\n",
    "    X_train = ohe.transform(X_train)\n",
    "    X_test = ohe.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "final_X_train, final_X_test = get_dummies(filtered_train.copy(), filtered_test.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_all_features(current_training_set, pairwise_cols):\n",
    "    all_features_combined = []\n",
    "    for feature_pair in pairwise_cols:\n",
    "        feature_name = str(feature_pair)\n",
    "        if feature_name not in current_training_set.columns:\n",
    "            combined_dict = {}\n",
    "            combined_features = current_training_set[feature_pair[0]] | current_training_set[feature_pair[1]]\n",
    "            combined_dict['feature_name'] = str(feature_pair)\n",
    "            combined_dict['feature_value'] = combined_features\n",
    "            if combined_features.equals(current_training_set[feature_pair[0]]) or combined_features.equals(current_training_set[feature_pair[1]]):\n",
    "                continue\n",
    "            else:\n",
    "                all_features_combined.append(combined_dict)\n",
    "    return all_features_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(final_X_train)\n",
    "pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "\n",
    "# print(\"Combinando features do nivel...\")\n",
    "# all_features_combined = _combine_all_features(final_X_train, pairwise_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_treino = final_X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001 23736 0.049014304416390486 - 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-77c5f968445e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhjmi_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_treino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e2ee9fbf4ac1>\u001b[0m in \u001b[0;36mhjmi_selector\u001b[0;34m(X, y, bins, max_features)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mjmi_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_k\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mjmi_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mX_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/pymit.py\u001b[0m in \u001b[0;36mI\u001b[0;34m(X, Y, bins)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mp_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mybins\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mp_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_xy\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mp_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mybins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36mhistogram2d\u001b[0;34m(x, y, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mxedges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myedges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxedges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myedges\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistogramdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogramdd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogramdd\u001b[0;34m(sample, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     '`bins[{}]` must be positive, when an integer'.format(i))\n\u001b[1;32m   1052\u001b[0m             \u001b[0msmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0medges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# see gh-7142. Hence, we multiply in place only for standard scalar types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0m_mult_inplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36misscalar\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \"\"\"\n\u001b[0;32m-> 1862\u001b[0;31m     return (isinstance(element, generic)\n\u001b[0m\u001b[1;32m   1863\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mScalarType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             or isinstance(element, numbers.Number))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hjmi_selector(_treino.copy(), y_train.copy(), bins=2, max_features=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2953    0\n",
       "1560    0\n",
       "2098    0\n",
       "71      0\n",
       "1636    0\n",
       "       ..\n",
       "2680    0\n",
       "1854    0\n",
       "217     0\n",
       "2164    1\n",
       "1697    0\n",
       "Name: ('191_9_4', '191_6_4'), Length: 2009, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 13:45:12,493\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aa2b744d9263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_features_combined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0m_treino\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2925\u001b[0m         \u001b[0;31m# see if we can slice the rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2926\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_index_sliceable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m             \u001b[0;31m# either we have a slice or we have a string that can be converted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mconvert_to_index_sliceable\u001b[0;34m(obj, key)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m         \u001b[0;31m# we are an actual column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2273\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3902\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOverflowError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-13 13:45:12,493\tERROR worker.py:1716 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2020-09-13 13:45:12,496\tERROR worker.py:1616 -- print_logs: Connection closed by server.\n"
     ]
    }
   ],
   "source": [
    "for feat in all_features_combined:\n",
    "    _treino[feat['feature_name']] = feat['feature_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGLOSS: 0.6593040135656834 - AUC: 0.6934654471544716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/basic/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "def run_initial_logit(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[y_train.columns[0]])\n",
    "    all_preds = clf.predict_proba(X_test)[:, 1]\n",
    "    logloss = metrics.log_loss(y_test[y_test.columns[0]], all_preds)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]], all_preds, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return clf, logloss, auc\n",
    "\n",
    "start_classifier, logloss, auc = run_initial_logit(final_X_train.copy(), y_train.copy(), final_X_test.copy(), y_test.copy())\n",
    "print(f\"LOGLOSS: {logloss} - AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_iterator(obj_ids):\n",
    "    \"\"\"\n",
    "    # https://github.com/ray-project/ray/issues/5554\n",
    "    \"\"\"\n",
    "    while obj_ids:\n",
    "        done, obj_ids = ray.wait(obj_ids)\n",
    "        yield ray.get(done[0])\n",
    "\n",
    "    \n",
    "def score_one_pair_parallel(combined_features, bsum, y_train):\n",
    "\n",
    "    def _calc_logloss(y_true, preds):\n",
    "        return metrics.log_loss(y_true[y_true.columns[0]], preds['preds'])\n",
    "\n",
    "    def _obj(x, \n",
    "             y_train,\n",
    "             combined_features,\n",
    "             bsum):\n",
    "\n",
    "        # add x to bsum\n",
    "        this_w = np.array(x).reshape(-1,1)\n",
    "        this_value = np.array(combined_features).reshape(1,-1)\n",
    "        bsum_with_new_feature = bsum + np.matmul(this_w.T, this_value)\n",
    "        this_preds = 1/(1 + np.exp(-bsum_with_new_feature)) \n",
    "        preds = pd.DataFrame(this_preds.reshape(-1,1), columns=['preds'])\n",
    "        return _calc_logloss(y_train, preds)\n",
    "    \n",
    "    \n",
    "    result = minimize(_obj, 1, args=(y_train,\n",
    "                             combined_features['feature_value'],\n",
    "                             bsum))\n",
    "\n",
    "    this_coef = result['x'][0]\n",
    "    this_logloss = result['fun']\n",
    "    dict_result_combination = {\"coef\":this_coef,\n",
    "                               \"logloss\" : this_logloss,\n",
    "                               \"feature\": combined_features['feature_name']}\n",
    "\n",
    "    return dict_result_combination\n",
    "\n",
    "\n",
    "def iter_one_level(X_train, y_train, X_test, y_test, coef_dict, intercept):\n",
    "    \n",
    "    def _combine_all_features(current_training_set, pairwise_cols):\n",
    "        all_features_combined = []\n",
    "        for feature_pair in pairwise_cols:\n",
    "            feature_name = str(feature_pair)\n",
    "            if feature_name not in current_training_set.columns:\n",
    "                combined_dict = {}\n",
    "                combined_features = current_training_set[feature_pair[0]] | current_training_set[feature_pair[1]]\n",
    "                combined_dict['feature_name'] = str(feature_pair)\n",
    "                combined_dict['feature_value'] = combined_features\n",
    "                if combined_features.equals(current_training_set[feature_pair[0]]) or combined_features.equals(current_training_set[feature_pair[1]]):\n",
    "                    continue\n",
    "                else:\n",
    "                    all_features_combined.append(combined_dict)\n",
    "        return all_features_combined\n",
    "    \n",
    "    def _chunker(seq, size):\n",
    "        return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "    \n",
    "    all_columns = list(X_train)\n",
    "    pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "    all_results = {}\n",
    "    col_coefs = np.array(list(coef_dict.values())).reshape(1,-1)\n",
    "    bsum = np.add(np.matmul(col_coefs, X_train.values.T), intercept)\n",
    "    \n",
    "    print(\"Combinando features do nivel...\")\n",
    "    all_features_combined = _combine_all_features(X_train, pairwise_cols)\n",
    "    print(f\"{len(all_features_combined)} pares criados\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(\"Iniciando paralelismo do nivel...\")\n",
    "    chunk = 0\n",
    "    chuncksize = int(10e3)\n",
    "    for group in _chunker(all_features_combined, chuncksize):\n",
    "        print(f\"\\t working in chunk {chunk}\")\n",
    "        score_one_pair_parallel_ray = ray.remote(score_one_pair_parallel)\n",
    "        results = [score_one_pair_parallel_ray.remote(ray.put(one_pair), bsum, ray.put(y_train)) for one_pair in group]\n",
    "        for x in tqdm(to_iterator(results), total=len(results)):\n",
    "            pass\n",
    "\n",
    "        all_results.append(ray.get(results))\n",
    "        chunk += chuncksize\n",
    "        \n",
    "    return sum(all_results, [])\n",
    "\n",
    "def predict_logit(coef_dict, intercept, X_test, y_test):\n",
    "    col_coefs = np.array(list(coef_dict.values())).reshape(1,-1)\n",
    "    bsum = np.add(np.matmul(col_coefs, X_test.values.T), intercept)\n",
    "    this_preds = 1/(1 + np.exp(-bsum)) \n",
    "    preds = pd.DataFrame(this_preds.reshape(-1,1), columns=['preds'])\n",
    "    logloss = metrics.log_loss(y_test[y_test.columns[0]], preds['preds'])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]],  preds['preds'], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return logloss, auc\n",
    "\n",
    "def beam_search(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def _choose_best_feature(level_results):\n",
    "        min_logloss = 9999\n",
    "        bsf_feature = None\n",
    "        bst_coef = None\n",
    "        for dict_feature in level_results:\n",
    "            if  dict_feature['logloss'] < min_logloss:\n",
    "                min_logloss = dict_feature['logloss']\n",
    "                bsf_feature = dict_feature['feature']\n",
    "                bst_coef = dict_feature['coef']\n",
    "        print(f\"Level - choose {bsf_feature} -{bst_coef} -{min_logloss}\")\n",
    "        return bsf_feature, bst_coef, min_logloss\n",
    "    \n",
    "    current_training_set = X_train.copy()\n",
    "    current_test_set = X_test.copy()\n",
    "    start_classifier, start_logloss, start_auc = run_initial_logit(current_training_set, y_train, current_test_set, y_test)\n",
    "    \n",
    "    coef_dict = dict(list(zip(current_training_set.columns,start_classifier.coef_[0])))\n",
    "    intercept = start_classifier.intercept_[0]\n",
    "    \n",
    "    print(f\"Start logloss : {start_logloss} - Start AUC {start_auc}\")\n",
    "    last_logloss = start_logloss\n",
    "    this_logloss = -np.inf\n",
    "    accepted_features = []\n",
    "    while this_logloss <= last_logloss:\n",
    "        # eval one level\n",
    "        level_results = iter_one_level(current_training_set, y_train, current_test_set, y_test, coef_dict, intercept)\n",
    "        bst_feature, this_coef, _ = _choose_best_feature(level_results)\n",
    "        \n",
    "        # update X_train an X_test\n",
    "        current_training_set[str(bst_feature)] = current_training_set[str(eval(bst_feature)[0])] | current_training_set[str(eval(bst_feature)[1])]\n",
    "        current_test_set[str(bst_feature)] = current_test_set[str(eval(bst_feature)[0])] | current_test_set[str(eval(bst_feature)[1])]\n",
    "        \n",
    "        # retrain logit with new feature\n",
    "#         this_clf, this_logloss, this_auc = run_initial_logit(current_training_set, y_train, current_test_set, y_test)\n",
    "#         coef_dict = dict(list(zip(current_training_set.columns,this_clf.coef_[0])))\n",
    "#         intercept = start_classifier.intercept_[0]\n",
    "        coef_dict[bst_feature] = this_coef\n",
    "        \n",
    "        this_logloss, this_auc = predict_logit(coef_dict, intercept, current_test_set, y_test)\n",
    "        print(f\" new  logloss: {this_logloss} - new auc {this_auc}\")\n",
    "        \n",
    "        coef_dict[bst_feature] = this_logloss\n",
    "    \n",
    "        current_logloss_diff = last_logloss - this_logloss\n",
    "        \n",
    "        if this_logloss > last_logloss:\n",
    "            current_training_set =  current_training_set.drop([str(bst_feature)], axis=1)\n",
    "            current_test_set =  current_test_set.drop([str(bst_feature)], axis=1)\n",
    "            coef_dict.pop(str(bst_feature), None)\n",
    "            \n",
    "        else:\n",
    "            last_logloss = this_logloss\n",
    "            \n",
    "        print(f\"logloss gain with {bst_feature}: {current_logloss_diff}\")\n",
    "    return current_training_set, current_test_set, coef_dict, intercept   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start logloss : 0.6549597108668569 - Start AUC 0.677545731707317\n",
      "Combinando features do nivel...\n",
      "271 pares criados\n",
      "Iniciando paralelismo do nivel...\n",
      "\t working in chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/serialization.py:176: FutureWarning: The SparseSeries class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  if isinstance(obj, pd.SparseSeries):\n",
      "/home/fernando.favoretti/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/serialization.py:165: FutureWarning: The SparseDataFrame class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  if isinstance(obj, pd.SparseDataFrame):\n"
     ]
    },
    {
     "ename": "ArrowIOError",
     "evalue": "Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-284b5e5a56ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplete_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplete_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_final_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_final_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-62-a7aadbcc6704>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mthis_logloss\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlast_logloss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# eval one level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mlevel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter_one_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_training_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_test_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mbst_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_choose_best_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-a7aadbcc6704>\u001b[0m in \u001b[0;36miter_one_level\u001b[0;34m(X_train, y_train, X_test, y_test, coef_dict, intercept)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t working in chunk {chunk}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mscore_one_pair_parallel_ray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_one_pair_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_one_pair_parallel_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-a7aadbcc6704>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\t working in chunk {chunk}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mscore_one_pair_parallel_ray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_one_pair_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscore_one_pair_parallel_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   2275\u001b[0m                 \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2276\u001b[0m             )\n\u001b[0;32m-> 2277\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2278\u001b[0m         \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mput_object\u001b[0;34m(self, object_id, value)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 range(ray_constants.DEFAULT_PUT_OBJECT_RETRIES)):\n\u001b[1;32m    397\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_store_and_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplasma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlasmaStoreFull\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplasma_exc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36m_try_store_and_register\u001b[0;34m(self, object_id, value)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \"\"\"\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_and_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplasma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPlasmaObjectExists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;31m# The object already exists in the object store, so there is no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mstore_and_register\u001b[0;34m(self, object_id, value, depth)\u001b[0m\n\u001b[1;32m    325\u001b[0m                         \u001b[0mmemcopy_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcopy_threads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                         serialization_context=self.get_serialization_context(\n\u001b[0;32m--> 327\u001b[0;31m                             self.current_job_id))\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializationCallbackError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0morig_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapper_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/_plasma.pyx\u001b[0m in \u001b[0;36mpyarrow._plasma.PlasmaClient.put\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/_plasma.pyx\u001b[0m in \u001b[0;36mpyarrow._plasma.PlasmaClient.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/_plasma.pyx\u001b[0m in \u001b[0;36mpyarrow._plasma.plasma_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/basic/lib/python3.7/site-packages/ray/pyarrow_files/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Broken pipe"
     ]
    }
   ],
   "source": [
    "complete_X_train, complete_X_test, coef_dict, intercept = beam_search(dummy_final_train, y_train, dummy_final_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
