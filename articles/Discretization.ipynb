{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to automate discretization and spare its dependence\n",
    "on human experts, we propose a multi-granularity discretization\n",
    "method. The basic idea is simple: instead of using a fine-tuned\n",
    "granularity, we discretize each numerical feature into several, rather\n",
    "than only one, categorical features, each with a different granularity.\n",
    "Figure 5 gives an illustration of discretizing a numerical feature\n",
    "with four levels of granularity. Since more levels of granularity are\n",
    "considered, it is more likely to get a promising result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar p = 5 primeiramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import operator\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize \n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = sklearn.datasets.load_boston()\n",
    "boston = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "\n",
    "boston['bin_lstat'] = boston['LSTAT'].apply(lambda x: 0 if x < 10 else 1)\n",
    "boston = boston.drop(['LSTAT'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A remaining problem is how to determine the\n",
    "levels of granularity. For an experienced user, it can set a group of\n",
    "potentially good values. If no values are specified, AutoCross will\n",
    "use {10^p\n",
    "}\n",
    "P\n",
    "p=1\n",
    "as default values, where P is an integer determined\n",
    "by a rule-based mechanism that considers the available memory,\n",
    "data size and feature numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_numeric_features(df, y_feature, max_gran=10):\n",
    "    \"\"\"\n",
    "    multi-granularity discretization\n",
    "    method. The basic idea is simple: instead of using a fine-tuned\n",
    "    granularity, we discretize each numerical feature into several, rather\n",
    "    than only one, categorical features, each with a different granularity.\n",
    "    \n",
    "    min granularity = 3\n",
    "    \n",
    "    Sometimes de edge values did not permit to execute correct discretization\n",
    "    if this happens the step is not executed\n",
    "    \"\"\"\n",
    "    is_numeric = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numeric_features = df.select_dtypes(include=is_numeric)\n",
    "    if y_feature in numeric_features:\n",
    "        numeric_features = numeric_features.drop([y_feature], axis=1)\n",
    "    discrete_features = []\n",
    "    print(f\"Discretizing {len(numeric_features.columns)} features...\")\n",
    "    for feat in numeric_features:\n",
    "        print(f\" Working in {feat}\")\n",
    "        for gran in range(3, max_gran+1):\n",
    "            try:\n",
    "                df[f\"{feat}_{gran}\"] = pd.qcut(df[feat],\n",
    "                                               gran,\n",
    "                                               labels= [f\"bin_{i}\" for i in range(gran)]\n",
    "                                              )\n",
    "                discrete_features.append(f\"{feat}_{gran}\")\n",
    "            except:\n",
    "                print(f\"Not possible to correct work on cut {feat} > {gran}\")\n",
    "                break\n",
    "        df = df.drop(feat, axis=1)\n",
    "        \n",
    "    return df, discrete_features\n",
    "\n",
    "\n",
    "def run_field_wise_minibatch_gradient_descent_lr(this_feature,\n",
    "                                                 y_feature,\n",
    "                                                 X_all,\n",
    "                                                 y_all,\n",
    "                                                 all_features=False,\n",
    "                                                 return_clf = False):\n",
    "    \"\"\"\n",
    "    Run field wise logistic regression\n",
    "    \"\"\"\n",
    "        \n",
    "    clf = linear_model.SGDClassifier(loss='log',\n",
    "                                     n_jobs= -1,\n",
    "                                     warm_start = True)\n",
    "    if all_features:\n",
    "        this_X = X_all\n",
    "        \n",
    "    else:\n",
    "        this_X = pd.get_dummies(X_all[this_feature], columns=this_feature)\n",
    "        \n",
    "#     for i in range(0, 1000):\n",
    "#         this_batch_samples = this_X.sample(frac=0.8)\n",
    "#         this_y = y_all.loc[y_all.index.isin(this_batch_samples.index)]\n",
    "#         clf.partial_fit(this_batch_samples, this_y[y_feature], classes=this_y[y_feature].unique())\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0).fit(this_X, y_all[y_feature])\n",
    "\n",
    "    if return_clf:\n",
    "        all_preds = clf.predict(this_X)\n",
    "        y_all['preds'] = all_preds\n",
    "        final_score = metrics.log_loss(y_all[y_feature], y_all['preds'])\n",
    "        return clf, final_score, y_all\n",
    "   \n",
    "    return clf.score(this_X, y_all)\n",
    "\n",
    "def measure_and_clean_discrete_features(df, discrete_features, y_feature):\n",
    "    \"\"\"\n",
    "    In order to avoid the dramatic increase in feature number caused\n",
    "    by discretization, once these features are generated, we use fieldwise LR to evaluate them and keep\n",
    "    only the best half. \n",
    "    \"\"\"\n",
    "    \n",
    "    def _select_discrete_features(feature_score, abs=True):\n",
    "        \"\"\"\n",
    "        Select only the best half of measured features\n",
    "        \"\"\"\n",
    "        if abs:\n",
    "            feature_score = {k: np.abs(v) for k,v in feature_score.items()}\n",
    "            \n",
    "        sorted_score = sorted(feature_score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        half_features = int(np.floor(len(sorted_score)/2))\n",
    "        return [k[0] for k in sorted_score[:half_features]]\n",
    "    \n",
    "    feature_score = {}\n",
    "    # while what you describe is properly called minibatch learning.\n",
    "    # That's implemented in sklearn.linear_model.SGDClassifier,\n",
    "    # which fits a logistic regression model if you give it the option loss=\"log\".\n",
    "    y_all = df[[y_feature]]\n",
    "    X_all = df.drop([y_feature], axis=1)\n",
    "    this_classifier, final_score, preds = run_field_wise_minibatch_gradient_descent_lr(X_all,\n",
    "                                                                          y_feature,\n",
    "                                                                          X_all,\n",
    "                                                                          y_all,\n",
    "                                                                         all_features=True,\n",
    "                                                                         return_clf=True)\n",
    "    \n",
    "    coef_dict = dict(list(zip(X_all.columns, this_classifier.coef_[0])))\n",
    "    return df[_select_discrete_features(coef_dict)], y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing 12 features...\n",
      " Working in CRIM\n",
      " Working in ZN\n",
      "Not possible to correct work on cut ZN > 3\n",
      " Working in INDUS\n",
      "Not possible to correct work on cut INDUS > 6\n",
      " Working in CHAS\n",
      "Not possible to correct work on cut CHAS > 3\n",
      " Working in NOX\n",
      " Working in RM\n",
      " Working in AGE\n",
      " Working in DIS\n",
      " Working in RAD\n",
      "Not possible to correct work on cut RAD > 4\n",
      " Working in TAX\n",
      "Not possible to correct work on cut TAX > 8\n",
      " Working in PTRATIO\n",
      "Not possible to correct work on cut PTRATIO > 6\n",
      " Working in B\n",
      "Not possible to correct work on cut B > 5\n"
     ]
    }
   ],
   "source": [
    "boston_discretize, discrete_features = discretize_numeric_features(boston.copy(), y_feature='bin_lstat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Favoretti\\Anaconda3\\envs\\master\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "original_feature_set = pd.get_dummies(boston_discretize)\n",
    "original_feature_set, y_all = measure_and_clean_discrete_features(original_feature_set.copy(),\n",
    "                                                    discrete_features,\n",
    "                                                    y_feature='bin_lstat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1604110558996328\n"
     ]
    }
   ],
   "source": [
    "start_classifier, final_score, preds = run_field_wise_minibatch_gradient_descent_lr(original_feature_set.columns,\n",
    "                                                                                        'bin_lstat',\n",
    "                                                                                        original_feature_set.copy(),\n",
    "                                                                                        y_all.copy(),\n",
    "                                                                                        all_features=True,\n",
    "                                                                                        return_clf=True)\n",
    "print(final_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_one_pair(original_feature_set, y_feature, feature_pair, coef_dict, intercept, y_all):\n",
    "    \n",
    "    def _calc_logloss(y_true, y_feature, preds):\n",
    "        return metrics.log_loss(y_true[y_feature], preds['preds'])\n",
    "\n",
    "\n",
    "    def _obj(x, \n",
    "            y_feature,\n",
    "            original_feature_set,\n",
    "            feature_pair,\n",
    "            coef_dict,\n",
    "            intercept,\n",
    "            y_true):\n",
    "\n",
    "        combined_features = original_feature_set[feature_pair[0]] | original_feature_set[feature_pair[1]]\n",
    "        col_coefs = np.array(list(coef_dict.values())).reshape(-1,1)\n",
    "        bsum = np.add(original_feature_set.values.dot(col_coefs), intercept)\n",
    "        # add x to bsum\n",
    "        bsum_with_new_feature = bsum + np.sum(np.dot(combined_features.values.reshape(-1,1), x))\n",
    "        this_preds = 1/(1 + np.exp(-bsum_with_new_feature)) \n",
    "\n",
    "        preds = pd.DataFrame(this_preds, columns=['preds'])\n",
    "        return _calc_logloss(y_true, y_feature, preds)\n",
    "    \n",
    "    \n",
    "\n",
    "    result = minimize(_obj, 0, args=(y_feature,\n",
    "                                    original_feature_set.copy(),\n",
    "                                    feature_pair,\n",
    "                                    coef_dict,\n",
    "                                    intercept,\n",
    "                                    y_all),\n",
    "                     method = 'Nelder-Mead')\n",
    "    \n",
    "    this_coef = np.round(result['x'][0],3)\n",
    "    this_logloss = result['fun']\n",
    "    \n",
    "    dict_result_combination = {\"coef\":this_coef,\n",
    "                               \"logloss\" : this_logloss}\n",
    "    \n",
    "    return dict_result_combination\n",
    "\n",
    "def iter_one_level(original_feature_set, y_feature, coef_dict, intercept, y_all):\n",
    "    \n",
    "    all_columns = list(original_feature_set)\n",
    "    pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "    all_results = {}\n",
    "    with tqdm(total=len(pairwise_cols)) as pbar:\n",
    "        for pair in pairwise_cols:\n",
    "            feature_name = str(pair)\n",
    "            if feature_name not in original_feature_set.columns:\n",
    "                all_results[feature_name] = score_one_pair(original_feature_set.copy(),\n",
    "                               y_feature,\n",
    "                               pair,\n",
    "                               coef_dict,\n",
    "                               intercept,\n",
    "                               y_all.copy())\n",
    "                pbar.update(1)\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def beam_search(original_feature_set, y_feature, y_all):\n",
    "    \n",
    "    def _choose_best_feature(dict_level_results):\n",
    "        min_logloss = 9999\n",
    "        min_key = None\n",
    "        this_coef = None\n",
    "        for key, val in dict_level_results.items():\n",
    "            if val['logloss'] < min_logloss:\n",
    "                min_logloss = val['logloss']\n",
    "                min_key = key\n",
    "                this_coef = val['coef']\n",
    "        print(f\"Level - choose {min_key} - logloss of {min_logloss}\")\n",
    "        return min_key, this_coef, min_logloss\n",
    "    \n",
    "    current_feature_set = original_feature_set.copy()\n",
    "    start_classifier, start_logloss, preds = run_field_wise_minibatch_gradient_descent_lr(original_feature_set.columns,\n",
    "                                                                                        'bin_lstat',\n",
    "                                                                                        original_feature_set.copy(),\n",
    "                                                                                        y_all.copy(),\n",
    "                                                                                        all_features=True,\n",
    "                                                                                        return_clf=True)\n",
    "    \n",
    "    coef_dict = dict(list(zip(current_feature_set.columns,start_classifier.coef_[0])))\n",
    "    intercept = start_classifier.intercept_[0]\n",
    "    \n",
    "    print(f\"Start score : {start_logloss}\")\n",
    "    \n",
    "    current_logloss_diff = start_logloss\n",
    "    accepted_features = []\n",
    "    while current_logloss_diff >= 0.1:\n",
    "    \n",
    "        dict_level_results = iter_one_level(current_feature_set.copy(),\n",
    "                   y_feature,\n",
    "                   coef_dict,\n",
    "                   intercept,\n",
    "                   y_all)\n",
    "\n",
    "        bst_feature, this_coef, this_logloss = _choose_best_feature(dict_level_results)\n",
    "        current_feature_set[str(bst_feature)] = current_feature_set[str(eval(bst_feature)[0])] | current_feature_set[str(eval(bst_feature)[1])]\n",
    "        coef_dict[bst_feature] = this_coef\n",
    "        current_logloss_diff = current_logloss_diff - this_logloss\n",
    "        if current_logloss_diff < 0.1:\n",
    "            current_feature_set =  current_feature_set.drop([str(bst_feature)], axis=1)\n",
    "        print(f\"logloss gain with {bst_feature}: {current_logloss_diff}\")\n",
    "    return current_feature_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 9/12561 [00:00<02:23, 87.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start score : 1.1604110558996328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12561/12561 [02:09<00:00, 97.24it/s]\n",
      "  0%|                                                                               | 10/12720 [00:00<02:15, 93.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'NOX_5_bin_4') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'NOX_5_bin_4'): 1.045798820998491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 12719/12720 [02:10<00:00, 97.59it/s]\n",
      "  0%|                                                                               | 10/12880 [00:00<02:19, 91.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'RM_8_bin_2') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'RM_8_bin_2'): 0.9311865860973492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 12878/12880 [02:12<00:00, 96.88it/s]\n",
      "  0%|                                                                               | 10/13041 [00:00<02:17, 94.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'AGE_8_bin_0') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'AGE_8_bin_0'): 0.8165743511962074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13038/13041 [02:13<00:00, 97.41it/s]\n",
      "  0%|                                                                               | 10/13203 [00:00<02:22, 92.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'CRIM_8_bin_7') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'CRIM_8_bin_7'): 0.7019621162950656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13199/13203 [02:16<00:00, 97.01it/s]\n",
      "  0%|                                                                               | 10/13366 [00:00<02:25, 91.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'CRIM_8_bin_5') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'CRIM_8_bin_5'): 0.5873498813939237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13361/13366 [02:17<00:00, 96.90it/s]\n",
      "  0%|                                                                               | 10/13530 [00:00<02:22, 94.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'NOX_10_bin_5') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'NOX_10_bin_5'): 0.472737646492782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13524/13530 [02:21<00:00, 95.90it/s]\n",
      "  0%|                                                                               | 10/13695 [00:00<02:17, 99.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'AGE_10_bin_0') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'AGE_10_bin_0'): 0.35812541159164024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13688/13695 [02:21<00:00, 97.04it/s]\n",
      "  0%|                                                                               | 10/13861 [00:00<02:27, 93.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'NOX_5_bin_2') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'NOX_5_bin_2'): 0.2435131766904985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 13853/13861 [02:23<00:00, 96.85it/s]\n",
      "  0%|                                                                               | 10/14028 [00:00<02:26, 95.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'NOX_9_bin_5') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'NOX_9_bin_5'): 0.12890094178935674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████▉| 14019/14028 [02:25<00:00, 96.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('NOX_10_bin_8', 'NOX_9_bin_7') - logloss of 0.11461223490114177\n",
      "logloss gain with ('NOX_10_bin_8', 'NOX_9_bin_7'): 0.014288706888214972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_feature = 'bin_lstat'\n",
    "t = beam_search(original_feature_set.copy(),\n",
    "            y_feature,\n",
    "            y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOX_10_bin_8', 'NOX_5_bin_4', 'RM_8_bin_2', 'AGE_8_bin_0',\n",
       "       'CRIM_8_bin_7', 'CRIM_8_bin_5', 'NOX_10_bin_5', 'AGE_10_bin_0',\n",
       "       'NOX_5_bin_2', 'NOX_9_bin_5',\n",
       "       ...\n",
       "       'CRIM_10_bin_1', '('NOX_10_bin_8', 'NOX_5_bin_4')',\n",
       "       '('NOX_10_bin_8', 'RM_8_bin_2')', '('NOX_10_bin_8', 'AGE_8_bin_0')',\n",
       "       '('NOX_10_bin_8', 'CRIM_8_bin_7')', '('NOX_10_bin_8', 'CRIM_8_bin_5')',\n",
       "       '('NOX_10_bin_8', 'NOX_10_bin_5')', '('NOX_10_bin_8', 'AGE_10_bin_0')',\n",
       "       '('NOX_10_bin_8', 'NOX_5_bin_2')', '('NOX_10_bin_8', 'NOX_9_bin_5')'],\n",
       "      dtype='object', length=168)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = t.columns\n",
    "pairwise_cols = list(itertools.combinations(all_columns, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(random_state=0),\n",
       " 1.228669507272974,\n",
       "      bin_lstat  preds\n",
       " 0            0      0\n",
       " 1            0      0\n",
       " 2            0      0\n",
       " 3            0      0\n",
       " 4            0      0\n",
       " ..         ...    ...\n",
       " 501          0      0\n",
       " 502          0      0\n",
       " 503          0      0\n",
       " 504          0      0\n",
       " 505          0      1\n",
       " \n",
       " [506 rows x 2 columns])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_field_wise_minibatch_gradient_descent_lr(t.columns,\n",
    "                                            'bin_lstat',\n",
    "                                            t.copy(),\n",
    "                                            y_all.copy(),\n",
    "                                            all_features=True,\n",
    "                                            return_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5351057228771896\n",
      "0.514191844462476\n",
      "0.44325648735939416\n",
      "0.47713712949262566\n",
      "0.5020683181391501\n",
      "0.3120932970582152\n",
      "0.38352186848678665\n",
      "0.2823015607846881\n",
      "0.42472912987446904\n",
      "0.5869091371931332\n",
      "0.3718836014191844\n",
      "0.4879480693045678\n",
      "0.4160421936900387\n",
      "0.35687238477081445\n",
      "0.3774521502553578\n",
      "0.5063799659523014\n",
      "0.3926781537874088\n",
      "0.5935675305872432\n",
      "0.48568087442126867\n",
      "0.6574228755986189\n",
      "0.4016116971345839\n",
      "0.3151003134297488\n",
      "0.25449063688288553\n",
      "0.5003818433487662\n",
      "0.3852162983469365\n",
      "0.5034922756272573\n",
      "0.3169140693363881\n",
      "0.3631250696068605\n",
      "0.3733155139770576\n",
      "0.5591300335703944\n",
      "0.5270154169252065\n",
      "0.47917362735271196\n",
      "0.5523523141297949\n",
      "0.46956390307543\n",
      "0.4224698900609359\n",
      "0.6431355702989515\n",
      "0.6554500182966605\n",
      "0.44380538717324547\n",
      "0.6431992108570792\n",
      "0.5859465737514519\n",
      "0.38883585509044916\n",
      "0.364692218350755\n",
      "0.5630598380347795\n",
      "0.5472053839912177\n",
      "0.436820835918731\n",
      "0.4804543935850317\n",
      "0.633637216998393\n",
      "0.4551572717292731\n",
      "0.5200785960892876\n",
      "0.4042050498782874\n",
      "0.6557523109477671\n",
      "0.3814217300685727\n",
      "0.46355782540212875\n",
      "0.5212957217634799\n",
      "0.6625379854581324\n",
      "0.49316659507103877\n",
      "0.4394062335926686\n",
      "0.4245700284791498\n",
      "0.5813564984964918\n",
      "0.6189839784894914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-aa9f82f566c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                             \u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                             \u001b[0mall_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                             return_clf=True)\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_lstat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-7a827757bd18>\u001b[0m in \u001b[0;36mrun_field_wise_minibatch_gradient_descent_lr\u001b[1;34m(this_feature, y_feature, X_all, y_all, all_features, return_clf)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mthis_batch_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mthis_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_batch_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_batch_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthis_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_clf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    692\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    523\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m                              max_iter=max_iter)\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    582\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                                               \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                                               random_state=self.random_state)\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m     \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     dataset, intercept_decay = make_dataset(\n\u001b[0;32m    415\u001b[0m         X, y_i, sample_weight, random_state=random_state)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.BitGenerator.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.SeedSequence.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.SeedSequence.get_assembled_entropy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in pairwise_cols:\n",
    "    t['x'] = t[col[0]] | t[col[1]]\n",
    "    _,_, preds = run_field_wise_minibatch_gradient_descent_lr(t.columns,\n",
    "                                            'bin_lstat',\n",
    "                                            t.copy(),\n",
    "                                            y_all.copy(),\n",
    "                                            all_features=True,\n",
    "                                            return_clf=True)\n",
    "    print(roc_auc_score(preds['bin_lstat'], preds['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4837637026076718"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "all_columns = list(original_feature_set)\n",
    "pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "all_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cols = pairwise_cols[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(original_feature_set, new_coef_dict):\n",
    "    col_coefs = np.array(list(new_coef_dict.values())).reshape(-1,1)\n",
    "    this_pred = np.add(np.round(original_feature_set.values.dot(col_coefs),3), intercept)\n",
    "    return 1/(1 + np.exp(-this_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.218"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_dict = coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature_set['teste_feature'] = original_feature_set['DIS_9_bin_1'] | original_feature_set['DIS_9_bin_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_dict['teste_feature'] = 0.218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all['new_preds'] = make_preds(original_feature_set, new_coef_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.60009471884184"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_all['bin_lstat'], y_all['new_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_lstat</th>\n",
       "      <th>new_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bin_lstat  new_preds\n",
       "0            0        0.0\n",
       "1            0        0.0\n",
       "2            0        0.0\n",
       "3            0        1.0\n",
       "4            0        0.0\n",
       "..         ...        ...\n",
       "501          0        1.0\n",
       "502          0        1.0\n",
       "503          0        1.0\n",
       "504          0        1.0\n",
       "505          0        0.0\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -18.59017554414894\n",
       " hess_inv: array([[1]])\n",
       "      jac: array([0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 9\n",
       "      nit: 1\n",
       "     njev: 3\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-5.05])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 5.552074997367714e-17\n",
       " hess_inv: array([[0.50000004]])\n",
       "      jac: array([-1.28826571e-12])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 21\n",
       "      nit: 4\n",
       "     njev: 7\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-7.45122473e-09])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x, a,b,c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "minimize(fun, 100, args=(1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -0.5860022592398136\n",
       " hess_inv: array([[1]])\n",
       "      jac: array([0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 3\n",
       "      nit: 0\n",
       "     njev: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['teste'] = np.round(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5860022592398136"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(preds['bin_lstat'], preds['teste'], pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_lstat</th>\n",
       "      <th>preds</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bin_lstat  preds  residual\n",
       "169          1  1.000     0.000\n",
       "447          1  0.484     0.516\n",
       "490          1  1.000     0.000\n",
       "473          1  1.000     0.000\n",
       "438          1  1.000     0.000\n",
       "149          1  1.000     0.000\n",
       "165          0  1.000    -1.000\n",
       "496          1  1.000     0.000\n",
       "337          1  0.000     1.000\n",
       "227          0  1.000    -1.000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.sort_values(['residual']).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000    295\n",
       " 1.000    133\n",
       "-1.000     53\n",
       " 0.996      2\n",
       "-0.199      2\n",
       " 0.990      1\n",
       " 0.125      1\n",
       "-0.108      1\n",
       "-0.044      1\n",
       " 0.218      1\n",
       "-0.036      1\n",
       "-0.120      1\n",
       "-0.790      1\n",
       "-0.976      1\n",
       "-0.998      1\n",
       "-0.999      1\n",
       " 0.516      1\n",
       "-0.001      1\n",
       "-0.846      1\n",
       "-0.958      1\n",
       "-0.917      1\n",
       "-0.996      1\n",
       "-0.952      1\n",
       " 0.979      1\n",
       " 0.998      1\n",
       " 0.975      1\n",
       "Name: residual, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals['residual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1/ (1 * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
