{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to automate discretization and spare its dependence\n",
    "on human experts, we propose a multi-granularity discretization\n",
    "method. The basic idea is simple: instead of using a fine-tuned\n",
    "granularity, we discretize each numerical feature into several, rather\n",
    "than only one, categorical features, each with a different granularity.\n",
    "Figure 5 gives an illustration of discretizing a numerical feature\n",
    "with four levels of granularity. Since more levels of granularity are\n",
    "considered, it is more likely to get a promising result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar p = 5 primeiramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-15 20:52:55,780\tINFO resource_spec.py:212 -- Starting Ray with 53.66 GiB memory available for workers and up to 26.84 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-15 20:52:56,006\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-07-15 20:52:56,268\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.96.22.5',\n",
       " 'raylet_ip_address': '10.96.22.5',\n",
       " 'redis_address': '10.96.22.5:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-15_20-52-55_778754_1582/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-15_20-52-55_778754_1582/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-07-15_20-52-55_778754_1582'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import operator\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize \n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from fangorn.files_prep import get_data, data_to_pandas\n",
    "from fangorn.preprocessing import splitting, feature_selection\n",
    "from fangorn.training import classifiers\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML_CHALLENGE files ready!\n"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "all_datasets = get_data.get_all_data(only='ml_challenge')\n",
    "this_dataset = 'madeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2009, 28)\n"
     ]
    }
   ],
   "source": [
    "# configure dataset\n",
    "X_all, y_all = data_to_pandas.read_prepare_data(this_dataset)\n",
    "X_all = feature_selection.extra_trees_feature_selection(X_all, y_all)\n",
    "dataset_split_dict = splitting.simple_train_test_val_split(X_all, y_all)\n",
    "\n",
    "X_train = dataset_split_dict['train']['X']\n",
    "y_train = dataset_split_dict['train']['y']\n",
    "X_test = dataset_split_dict['test']['X']\n",
    "y_test = dataset_split_dict['test']['y']\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bank = pd.read_csv('bank.csv', sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "bank['y'] = bank['y'].map({'yes': 1, 'no':0})\n",
    "y = bank[['y']]\n",
    "X = bank.drop(['y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A remaining problem is how to determine the\n",
    "levels of granularity. For an experienced user, it can set a group of\n",
    "potentially good values. If no values are specified, AutoCross will\n",
    "use {10^p\n",
    "}\n",
    "P\n",
    "p=1\n",
    "as default values, where P is an integer determined\n",
    "by a rule-based mechanism that considers the available memory,\n",
    "data size and feature numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_numeric_features(X_train, X_test, max_gran=5):\n",
    "    \"\"\"\n",
    "    multi-granularity discretization\n",
    "    method. The basic idea is simple: instead of using a fine-tuned\n",
    "    granularity, we discretize each numerical feature into several, rather\n",
    "    than only one, categorical features, each with a different granularity.\n",
    "    \n",
    "    min granularity = 3\n",
    "    \n",
    "    Sometimes de edge values did not permit to execute correct discretization\n",
    "    if this happens the step is not executed\n",
    "    \"\"\"\n",
    "    \n",
    "    # separa dados numericos que precisam de binarizacao\n",
    "    is_numeric = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    numeric_features = X_train.select_dtypes(include=is_numeric)\n",
    "    discrete_features = []\n",
    "    print(f\"Discretizing {len(numeric_features.columns)} features...\")\n",
    "    for feat in numeric_features:\n",
    "        print(f\" Working in {feat}\")\n",
    "        for gran in range(2, max_gran+1):\n",
    "            try:\n",
    "                # calcula retibins no treino e aplica no teste\n",
    "                X_train[f\"{feat}_{gran}\"], this_bins = pd.qcut(X_train[feat],\n",
    "                                               gran,\n",
    "                                               labels= [f\"bin_{i}\" for i in range(gran)],\n",
    "                                               retbins = True\n",
    "                                              )\n",
    "                # aumenta range dos bins para garantir abrangencia\n",
    "                this_bins = np.concatenate(([-np.inf], this_bins[1:-1], [np.inf]))\n",
    "                \n",
    "                # aplicando no teste\n",
    "                X_test[f\"{feat}_{gran}\"] = pd.cut(X_test[feat], bins=this_bins, labels=[f\"bin_{i}\" for i in range(gran)])\n",
    "                \n",
    "                discrete_features.append(f\"{feat}_{gran}\")\n",
    "            except:\n",
    "                print(f\"Not possible to correct work on cut {feat} > {gran}\")\n",
    "                break\n",
    "        X_train = X_train.drop(feat, axis=1)\n",
    "        X_test = X_test.drop(feat, axis=1)\n",
    "        \n",
    "    return X_train, X_test, discrete_features\n",
    "\n",
    "def get_dummies(X_train, X_test):\n",
    "    ohe = OneHotEncoder(cols=X_train.columns).fit(X=X_train)\n",
    "    X_train = ohe.transform(X_train)\n",
    "    X_test = ohe.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def run_field_wise_minibatch_gradient_descent_lr(this_feature,\n",
    "                                                 X_all,\n",
    "                                                 y_all,\n",
    "                                                 y_feature,\n",
    "                                                 all_features=False,\n",
    "                                                 return_clf = False):\n",
    "    \"\"\"\n",
    "    Run field wise logistic regression\n",
    "    \"\"\"\n",
    "        \n",
    "    clf = linear_model.SGDClassifier(loss='log',\n",
    "                                     n_jobs= -1,\n",
    "                                     warm_start = True)\n",
    "    if all_features:\n",
    "        this_X = X_all\n",
    "        \n",
    "    else:\n",
    "        this_X = pd.get_dummies(X_all[this_feature], columns=this_feature)\n",
    "        \n",
    "#     for i in range(0, 1000):\n",
    "#         this_batch_samples = this_X.sample(frac=0.8)\n",
    "#         this_y = y_all.loc[y_all.index.isin(this_batch_samples.index)]\n",
    "#         clf.partial_fit(this_batch_samples, this_y[y_feature], classes=this_y[y_feature].unique())\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0, max_iter=10000).fit(this_X, y_all[y_feature])\n",
    "\n",
    "    if return_clf:\n",
    "        all_preds = clf.predict_proba(this_X)\n",
    "        y_all['preds'] = all_preds\n",
    "        final_score = metrics.log_loss(y_all[y_feature], y_all['preds'])\n",
    "        return clf, final_score, y_all\n",
    "   \n",
    "    return clf.score(this_X, y_all)\n",
    "\n",
    "\n",
    "def run_initial_logit(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train[y_train.columns[0]])\n",
    "    all_preds = clf.predict_proba(X_test)[:, 1]\n",
    "    logloss = metrics.log_loss(y_test[y_test.columns[0]], all_preds)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]], all_preds, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return clf, logloss, auc\n",
    "    \n",
    "\n",
    "def measure_and_clean_discrete_features(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    In order to avoid the dramatic increase in feature number caused\n",
    "    by discretization, once these features are generated, we use fieldwise LR to evaluate them and keep\n",
    "    only the best half. \n",
    "    \"\"\"\n",
    "    \n",
    "    def _select_discrete_features(feature_score, abs=True):\n",
    "        \"\"\"\n",
    "        Select only the best half of measured features\n",
    "        \"\"\"\n",
    "        if abs:\n",
    "            feature_score = {k: np.abs(v) for k,v in feature_score.items()}\n",
    "            \n",
    "        sorted_score = sorted(feature_score.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        half_features = int(np.floor(len(sorted_score)*0.5))\n",
    "        return [k[0] for k in sorted_score[:half_features]]\n",
    "    \n",
    "    feature_score = {}\n",
    "    # while what you describe is properly called minibatch learning.\n",
    "    # That's implemented in sklearn.linear_model.SGDClassifier,\n",
    "    # which fits a logistic regression model if you give it the option loss=\"log\".\n",
    "    this_classifier, logloss, auc = run_initial_logit(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    coef_dict = dict(list(zip(X_train.columns, this_classifier.coef_[0])))\n",
    "    selected_features = _select_discrete_features(coef_dict)\n",
    "    \n",
    "    return X_train[selected_features], X_test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discretizing 28 features...\n",
      " Working in 0\n",
      " Working in 1\n",
      " Working in 2\n",
      " Working in 3\n",
      " Working in 4\n",
      " Working in 5\n",
      " Working in 6\n",
      " Working in 7\n",
      " Working in 8\n",
      " Working in 9\n",
      " Working in 10\n",
      " Working in 11\n",
      " Working in 12\n",
      " Working in 13\n",
      " Working in 14\n",
      " Working in 15\n",
      " Working in 16\n",
      " Working in 17\n",
      " Working in 18\n",
      " Working in 19\n",
      " Working in 20\n",
      " Working in 21\n",
      " Working in 22\n",
      " Working in 23\n",
      " Working in 24\n",
      " Working in 25\n",
      " Working in 26\n",
      " Working in 27\n"
     ]
    }
   ],
   "source": [
    "X_train_disretized, X_test_discretized, discrete_features = discretize_numeric_features(X_train.copy(), X_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_2</th>\n",
       "      <th>0_3</th>\n",
       "      <th>0_4</th>\n",
       "      <th>0_5</th>\n",
       "      <th>1_2</th>\n",
       "      <th>1_3</th>\n",
       "      <th>1_4</th>\n",
       "      <th>1_5</th>\n",
       "      <th>2_2</th>\n",
       "      <th>2_3</th>\n",
       "      <th>...</th>\n",
       "      <th>25_4</th>\n",
       "      <th>25_5</th>\n",
       "      <th>26_2</th>\n",
       "      <th>26_3</th>\n",
       "      <th>26_4</th>\n",
       "      <th>26_5</th>\n",
       "      <th>27_2</th>\n",
       "      <th>27_3</th>\n",
       "      <th>27_4</th>\n",
       "      <th>27_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2953</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1636</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1854</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2164</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1697</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>...</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_1</td>\n",
       "      <td>bin_2</td>\n",
       "      <td>bin_3</td>\n",
       "      <td>bin_4</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "      <td>bin_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_2    0_3    0_4    0_5    1_2    1_3    1_4    1_5    2_2    2_3  \\\n",
       "2953  bin_0  bin_0  bin_0  bin_0  bin_0  bin_0  bin_0  bin_0  bin_1  bin_2   \n",
       "1560  bin_1  bin_2  bin_2  bin_3  bin_0  bin_0  bin_0  bin_0  bin_1  bin_1   \n",
       "2098  bin_0  bin_0  bin_0  bin_0  bin_0  bin_0  bin_1  bin_1  bin_1  bin_2   \n",
       "71    bin_0  bin_0  bin_0  bin_0  bin_0  bin_1  bin_1  bin_2  bin_0  bin_1   \n",
       "1636  bin_1  bin_2  bin_2  bin_3  bin_0  bin_0  bin_0  bin_0  bin_0  bin_0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2680  bin_1  bin_2  bin_3  bin_4  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0   \n",
       "1854  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0  bin_0  bin_1  bin_1  bin_1   \n",
       "217   bin_1  bin_1  bin_2  bin_3  bin_0  bin_0  bin_0  bin_0  bin_1  bin_2   \n",
       "2164  bin_1  bin_2  bin_3  bin_3  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0   \n",
       "1697  bin_1  bin_1  bin_2  bin_3  bin_1  bin_2  bin_3  bin_4  bin_1  bin_2   \n",
       "\n",
       "      ...   25_4   25_5   26_2   26_3   26_4   26_5   27_2   27_3   27_4  \\\n",
       "2953  ...  bin_1  bin_2  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0  bin_0   \n",
       "1560  ...  bin_3  bin_4  bin_1  bin_1  bin_2  bin_2  bin_0  bin_0  bin_0   \n",
       "2098  ...  bin_2  bin_2  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0  bin_1   \n",
       "71    ...  bin_2  bin_2  bin_0  bin_1  bin_1  bin_2  bin_1  bin_1  bin_2   \n",
       "1636  ...  bin_2  bin_2  bin_0  bin_0  bin_0  bin_0  bin_0  bin_1  bin_1   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2680  ...  bin_1  bin_2  bin_0  bin_0  bin_1  bin_1  bin_1  bin_2  bin_3   \n",
       "1854  ...  bin_3  bin_4  bin_1  bin_1  bin_2  bin_3  bin_1  bin_1  bin_2   \n",
       "217   ...  bin_2  bin_3  bin_1  bin_2  bin_3  bin_3  bin_0  bin_0  bin_0   \n",
       "2164  ...  bin_0  bin_1  bin_0  bin_0  bin_0  bin_0  bin_1  bin_2  bin_3   \n",
       "1697  ...  bin_3  bin_3  bin_1  bin_2  bin_3  bin_4  bin_0  bin_0  bin_0   \n",
       "\n",
       "       27_5  \n",
       "2953  bin_0  \n",
       "1560  bin_0  \n",
       "2098  bin_1  \n",
       "71    bin_3  \n",
       "1636  bin_2  \n",
       "...     ...  \n",
       "2680  bin_4  \n",
       "1854  bin_3  \n",
       "217   bin_0  \n",
       "2164  bin_3  \n",
       "1697  bin_0  \n",
       "\n",
       "[2009 rows x 112 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_disretized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_2_1</th>\n",
       "      <th>0_2_2</th>\n",
       "      <th>0_3_1</th>\n",
       "      <th>0_3_2</th>\n",
       "      <th>0_3_3</th>\n",
       "      <th>0_4_1</th>\n",
       "      <th>0_4_2</th>\n",
       "      <th>0_4_3</th>\n",
       "      <th>0_4_4</th>\n",
       "      <th>0_5_1</th>\n",
       "      <th>...</th>\n",
       "      <th>27_3_3</th>\n",
       "      <th>27_4_1</th>\n",
       "      <th>27_4_2</th>\n",
       "      <th>27_4_3</th>\n",
       "      <th>27_4_4</th>\n",
       "      <th>27_5_1</th>\n",
       "      <th>27_5_2</th>\n",
       "      <th>27_5_3</th>\n",
       "      <th>27_5_4</th>\n",
       "      <th>27_5_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1636</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009 rows × 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0_2_1  0_2_2  0_3_1  0_3_2  0_3_3  0_4_1  0_4_2  0_4_3  0_4_4  0_5_1  \\\n",
       "2953      1      0      1      0      0      1      0      0      0      1   \n",
       "1560      0      1      0      0      1      0      0      1      0      0   \n",
       "2098      1      0      1      0      0      1      0      0      0      1   \n",
       "71        1      0      1      0      0      1      0      0      0      1   \n",
       "1636      0      1      0      0      1      0      0      1      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2680      0      1      0      0      1      0      0      0      1      0   \n",
       "1854      0      1      0      0      1      0      0      0      1      0   \n",
       "217       0      1      0      1      0      0      0      1      0      0   \n",
       "2164      0      1      0      0      1      0      0      0      1      0   \n",
       "1697      0      1      0      1      0      0      0      1      0      0   \n",
       "\n",
       "      ...  27_3_3  27_4_1  27_4_2  27_4_3  27_4_4  27_5_1  27_5_2  27_5_3  \\\n",
       "2953  ...       0       1       0       0       0       1       0       0   \n",
       "1560  ...       0       1       0       0       0       1       0       0   \n",
       "2098  ...       0       0       1       0       0       0       1       0   \n",
       "71    ...       0       0       0       1       0       0       0       0   \n",
       "1636  ...       0       0       1       0       0       0       0       1   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2680  ...       1       0       0       0       1       0       0       0   \n",
       "1854  ...       0       0       0       1       0       0       0       0   \n",
       "217   ...       0       1       0       0       0       1       0       0   \n",
       "2164  ...       1       0       0       0       1       0       0       0   \n",
       "1697  ...       0       1       0       0       0       1       0       0   \n",
       "\n",
       "      27_5_4  27_5_5  \n",
       "2953       0       0  \n",
       "1560       0       0  \n",
       "2098       0       0  \n",
       "71         1       0  \n",
       "1636       0       0  \n",
       "...      ...     ...  \n",
       "2680       0       1  \n",
       "1854       1       0  \n",
       "217        0       0  \n",
       "2164       1       0  \n",
       "1697       0       0  \n",
       "\n",
       "[2009 rows x 392 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.14 s, sys: 320 ms, total: 3.46 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_dummy, X_test_dummy = get_dummies(X_train_disretized.copy(), X_test_discretized.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/master/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "final_X_train, final_X_test = measure_and_clean_discrete_features(X_train_dummy.copy(), y_train.copy(), X_test_dummy.copy(), y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGLOSS: 0.6649533504730653 - AUC: 0.6765447154471544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/master/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "start_classifier, logloss, auc = run_initial_logit(final_X_train.copy(), y_train.copy(), final_X_test.copy(), y_test.copy())\n",
    "print(f\"LOGLOSS: {logloss} - AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_iterator(obj_ids):\n",
    "    \"\"\"\n",
    "    # https://github.com/ray-project/ray/issues/5554\n",
    "    \"\"\"\n",
    "    while obj_ids:\n",
    "        done, obj_ids = ray.wait(obj_ids)\n",
    "        yield ray.get(done[0])\n",
    "\n",
    "    \n",
    "def score_one_pair_parallel(combined_features, bsum, y_train):\n",
    "\n",
    "    def _calc_logloss(y_true, preds):\n",
    "        return metrics.log_loss(y_true[y_true.columns[0]], preds['preds'])\n",
    "\n",
    "    def _obj(x, \n",
    "             y_train,\n",
    "             combined_features,\n",
    "             bsum):\n",
    "\n",
    "        # add x to bsum\n",
    "        this_w = np.array(x).reshape(-1,1)\n",
    "        this_value = np.array(combined_features).reshape(1,-1)\n",
    "        bsum_with_new_feature = bsum + np.matmul(this_w.T, this_value)\n",
    "        this_preds = 1/(1 + np.exp(-bsum_with_new_feature)) \n",
    "        preds = pd.DataFrame(this_preds.reshape(-1,1), columns=['preds'])\n",
    "        return _calc_logloss(y_train, preds)\n",
    "    \n",
    "    \n",
    "    result = minimize(_obj, 1, args=(y_train,\n",
    "                             combined_features['feature_value'],\n",
    "                             bsum))\n",
    "\n",
    "    this_coef = result['x'][0]\n",
    "    this_logloss = result['fun']\n",
    "    dict_result_combination = {\"coef\":this_coef,\n",
    "                               \"logloss\" : this_logloss,\n",
    "                               \"feature\": combined_features['feature_name']}\n",
    "\n",
    "    return dict_result_combination\n",
    "\n",
    "\n",
    "def iter_one_level(X_train, y_train, X_test, y_test, coef_dict, intercept):\n",
    "    \n",
    "    def _combine_all_features(current_training_set, pairwise_cols):\n",
    "        all_features_combined = []\n",
    "        for feature_pair in pairwise_cols:\n",
    "            feature_name = str(feature_pair)\n",
    "            if feature_name not in current_training_set.columns:\n",
    "                combined_dict = {}\n",
    "                combined_features = current_training_set[feature_pair[0]] | current_training_set[feature_pair[1]]\n",
    "                combined_dict['feature_name'] = str(feature_pair)\n",
    "                combined_dict['feature_value'] = combined_features\n",
    "                if combined_features.equals(current_training_set[feature_pair[0]]) or combined_features.equals(current_training_set[feature_pair[1]]):\n",
    "                    continue\n",
    "                else:\n",
    "                    all_features_combined.append(combined_dict)\n",
    "        return all_features_combined\n",
    "    \n",
    "    def _chunker(seq, size):\n",
    "        return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "    \n",
    "    all_columns = list(X_train)\n",
    "    pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "    all_results = {}\n",
    "    col_coefs = np.array(list(coef_dict.values())).reshape(1,-1)\n",
    "    bsum = np.add(np.matmul(col_coefs, X_train.values.T), intercept)\n",
    "    \n",
    "    print(\"Combinando features do nivel...\")\n",
    "    all_features_combined = _combine_all_features(X_train, pairwise_cols)\n",
    "    print(f\"{len(all_features_combined)} pares criados\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(\"Iniciando paralelismo do nivel...\")\n",
    "    chunk = 0\n",
    "    chuncksize = int(10e3)\n",
    "    for group in _chunker(all_features_combined, chuncksize):\n",
    "        print(f\"\\t working in chunk {chunk}\")\n",
    "        score_one_pair_parallel_ray = ray.remote(score_one_pair_parallel)\n",
    "        results = [score_one_pair_parallel_ray.remote(ray.put(one_pair), bsum, ray.put(y_train)) for one_pair in group]\n",
    "        for x in tqdm(to_iterator(results), total=len(results)):\n",
    "            pass\n",
    "\n",
    "        all_results.append(ray.get(results))\n",
    "        chunk += chuncksize\n",
    "        \n",
    "    return sum(all_results, [])\n",
    "\n",
    "def predict_logit(coef_dict, intercept, X_test, y_test):\n",
    "    col_coefs = np.array(list(coef_dict.values())).reshape(1,-1)\n",
    "    bsum = np.add(np.matmul(col_coefs, X_test.values.T), intercept)\n",
    "    this_preds = 1/(1 + np.exp(-bsum)) \n",
    "    preds = pd.DataFrame(this_preds.reshape(-1,1), columns=['preds'])\n",
    "    logloss = metrics.log_loss(y_test[y_test.columns[0]], preds['preds'])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]],  preds['preds'], pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return logloss, auc\n",
    "\n",
    "def beam_search(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    def _choose_best_feature(level_results):\n",
    "        min_logloss = 9999\n",
    "        bsf_feature = None\n",
    "        bst_coef = None\n",
    "        for dict_feature in level_results:\n",
    "            if  dict_feature['logloss'] < min_logloss:\n",
    "                min_logloss = dict_feature['logloss']\n",
    "                bsf_feature = dict_feature['feature']\n",
    "                bst_coef = dict_feature['coef']\n",
    "        print(f\"Level - choose {bsf_feature} -{bst_coef} -{min_logloss}\")\n",
    "        return bsf_feature, bst_coef, min_logloss\n",
    "    \n",
    "    current_training_set = X_train.copy()\n",
    "    current_test_set = X_test.copy()\n",
    "    start_classifier, start_logloss, start_auc = run_initial_logit(current_training_set, y_train, current_test_set, y_test)\n",
    "    \n",
    "    coef_dict = dict(list(zip(current_training_set.columns,start_classifier.coef_[0])))\n",
    "    intercept = start_classifier.intercept_[0]\n",
    "    \n",
    "    print(f\"Start logloss : {start_logloss} - Start AUC {start_auc}\")\n",
    "    last_logloss = start_logloss\n",
    "    this_logloss = -np.inf\n",
    "    accepted_features = []\n",
    "    while this_logloss <= last_logloss:\n",
    "        # eval one level\n",
    "        level_results = iter_one_level(current_training_set, y_train, current_test_set, y_test, coef_dict, intercept)\n",
    "        bst_feature, this_coef, _ = _choose_best_feature(level_results)\n",
    "        \n",
    "        # update X_train an X_test\n",
    "        current_training_set[str(bst_feature)] = current_training_set[str(eval(bst_feature)[0])] | current_training_set[str(eval(bst_feature)[1])]\n",
    "        current_test_set[str(bst_feature)] = current_test_set[str(eval(bst_feature)[0])] | current_test_set[str(eval(bst_feature)[1])]\n",
    "        \n",
    "        # retrain logit with new feature\n",
    "#         this_clf, this_logloss, this_auc = run_initial_logit(current_training_set, y_train, current_test_set, y_test)\n",
    "#         coef_dict = dict(list(zip(current_training_set.columns,this_clf.coef_[0])))\n",
    "#         intercept = start_classifier.intercept_[0]\n",
    "        coef_dict[bst_feature] = this_coef\n",
    "        \n",
    "        this_logloss, this_auc = predict_logit(coef_dict, intercept, current_test_set, y_test)\n",
    "        print(f\" new  logloss: {this_logloss} - new auc {this_auc}\")\n",
    "        \n",
    "        coef_dict[bst_feature] = this_logloss\n",
    "    \n",
    "        current_logloss_diff = last_logloss - this_logloss\n",
    "        \n",
    "        if this_logloss > last_logloss:\n",
    "            current_training_set =  current_training_set.drop([str(bst_feature)], axis=1)\n",
    "            current_test_set =  current_test_set.drop([str(bst_feature)], axis=1)\n",
    "            coef_dict.pop(str(bst_feature), None)\n",
    "            \n",
    "        else:\n",
    "            last_logloss = this_logloss\n",
    "            \n",
    "        print(f\"logloss gain with {bst_feature}: {current_logloss_diff}\")\n",
    "    return current_training_set, current_test_set, coef_dict, intercept   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernando.favoretti/anaconda3/envs/master/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start logloss : 0.6649533504730653 - Start AUC 0.6765447154471544\n",
      "Combinando features do nivel...\n",
      "18915 pares criados\n",
      "Iniciando paralelismo do nivel...\n",
      "\t working in chunk 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:17<00:00, 574.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t working in chunk 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8915/8915 [00:13<00:00, 640.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level - choose ('12_2_2', '9_2_2') --0.20469146092846477 -0.5545985753777033\n",
      " new  logloss: 0.6674501797484571 - new auc 0.6802642276422765\n",
      "logloss gain with ('12_2_2', '9_2_2'): -0.002496829275391854\n"
     ]
    }
   ],
   "source": [
    "complete_X_train, complete_X_test, coef_dict, intercept = beam_search(final_X_train, y_train, final_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_coefs = np.array(list(coef_dict.values())).reshape(1,-1)\n",
    "bsum = np.add(np.matmul(col_coefs, complete_X_test.values.T), intercept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_preds = 1/(1 + np.exp(-bsum)) \n",
    "preds = pd.DataFrame(this_preds.reshape(-1,1), columns=['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds =  preds['preds']\n",
    "logloss = metrics.log_loss(y_test[y_test.columns[0]], all_preds)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test[y_test.columns[0]], all_preds, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078039396921537"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOX_10_bin_8', 'NOX_5_bin_4', 'RM_8_bin_2', 'AGE_8_bin_0',\n",
       "       'CRIM_8_bin_7', 'CRIM_8_bin_5', 'NOX_10_bin_5', 'AGE_10_bin_0',\n",
       "       'NOX_5_bin_2', 'NOX_9_bin_5',\n",
       "       ...\n",
       "       'CRIM_10_bin_1', '('NOX_10_bin_8', 'NOX_5_bin_4')',\n",
       "       '('NOX_10_bin_8', 'RM_8_bin_2')', '('NOX_10_bin_8', 'AGE_8_bin_0')',\n",
       "       '('NOX_10_bin_8', 'CRIM_8_bin_7')', '('NOX_10_bin_8', 'CRIM_8_bin_5')',\n",
       "       '('NOX_10_bin_8', 'NOX_10_bin_5')', '('NOX_10_bin_8', 'AGE_10_bin_0')',\n",
       "       '('NOX_10_bin_8', 'NOX_5_bin_2')', '('NOX_10_bin_8', 'NOX_9_bin_5')'],\n",
       "      dtype='object', length=168)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.columnsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = t.columns\n",
    "pairwise_cols = list(itertools.combinations(all_columns, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(random_state=0),\n",
       " 1.228669507272974,\n",
       "      bin_lstat  preds\n",
       " 0            0      0\n",
       " 1            0      0\n",
       " 2            0      0\n",
       " 3            0      0\n",
       " 4            0      0\n",
       " ..         ...    ...\n",
       " 501          0      0\n",
       " 502          0      0\n",
       " 503          0      0\n",
       " 504          0      0\n",
       " 505          0      1\n",
       " \n",
       " [506 rows x 2 columns])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_field_wise_minibatch_gradient_descent_lr(t.columns,\n",
    "                                            'bin_lstat',\n",
    "                                            t.copy(),\n",
    "                                            y_all.copy(),\n",
    "                                            all_features=True,\n",
    "                                            return_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5351057228771896\n",
      "0.514191844462476\n",
      "0.44325648735939416\n",
      "0.47713712949262566\n",
      "0.5020683181391501\n",
      "0.3120932970582152\n",
      "0.38352186848678665\n",
      "0.2823015607846881\n",
      "0.42472912987446904\n",
      "0.5869091371931332\n",
      "0.3718836014191844\n",
      "0.4879480693045678\n",
      "0.4160421936900387\n",
      "0.35687238477081445\n",
      "0.3774521502553578\n",
      "0.5063799659523014\n",
      "0.3926781537874088\n",
      "0.5935675305872432\n",
      "0.48568087442126867\n",
      "0.6574228755986189\n",
      "0.4016116971345839\n",
      "0.3151003134297488\n",
      "0.25449063688288553\n",
      "0.5003818433487662\n",
      "0.3852162983469365\n",
      "0.5034922756272573\n",
      "0.3169140693363881\n",
      "0.3631250696068605\n",
      "0.3733155139770576\n",
      "0.5591300335703944\n",
      "0.5270154169252065\n",
      "0.47917362735271196\n",
      "0.5523523141297949\n",
      "0.46956390307543\n",
      "0.4224698900609359\n",
      "0.6431355702989515\n",
      "0.6554500182966605\n",
      "0.44380538717324547\n",
      "0.6431992108570792\n",
      "0.5859465737514519\n",
      "0.38883585509044916\n",
      "0.364692218350755\n",
      "0.5630598380347795\n",
      "0.5472053839912177\n",
      "0.436820835918731\n",
      "0.4804543935850317\n",
      "0.633637216998393\n",
      "0.4551572717292731\n",
      "0.5200785960892876\n",
      "0.4042050498782874\n",
      "0.6557523109477671\n",
      "0.3814217300685727\n",
      "0.46355782540212875\n",
      "0.5212957217634799\n",
      "0.6625379854581324\n",
      "0.49316659507103877\n",
      "0.4394062335926686\n",
      "0.4245700284791498\n",
      "0.5813564984964918\n",
      "0.6189839784894914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-aa9f82f566c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                             \u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                             \u001b[0mall_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                             return_clf=True)\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_lstat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'preds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-7a827757bd18>\u001b[0m in \u001b[0;36mrun_field_wise_minibatch_gradient_descent_lr\u001b[1;34m(this_feature, y_feature, X_all, y_all, all_features, return_clf)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mthis_batch_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mthis_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_batch_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_batch_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthis_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_feature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_clf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, sample_weight)\u001b[0m\n\u001b[0;32m    692\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m                                  \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                                  coef_init=None, intercept_init=None)\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     def fit(self, X, y, coef_init=None, intercept_init=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    523\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m                              max_iter=max_iter)\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    582\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                                               \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m                                               random_state=self.random_state)\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0my_i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m     \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     dataset, intercept_decay = make_dataset(\n\u001b[0;32m    415\u001b[0m         X, y_i, sample_weight, random_state=random_state)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\master\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_random_state\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_mt19937.pyx\u001b[0m in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.BitGenerator.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.SeedSequence.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36mnumpy.random._bit_generator.SeedSequence.get_assembled_entropy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for col in pairwise_cols:\n",
    "    t['x'] = t[col[0]] | t[col[1]]\n",
    "    _,_, preds = run_field_wise_minibatch_gradient_descent_lr(t.columns,\n",
    "                                            'bin_lstat',\n",
    "                                            t.copy(),\n",
    "                                            y_all.copy(),\n",
    "                                            all_features=True,\n",
    "                                            return_clf=True)\n",
    "    print(roc_auc_score(preds['bin_lstat'], preds['preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4837637026076718"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "all_columns = list(original_feature_set)\n",
    "pairwise_cols = list(itertools.combinations(all_columns, 2))\n",
    "all_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_cols = pairwise_cols[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(original_feature_set, new_coef_dict):\n",
    "    col_coefs = np.array(list(new_coef_dict.values())).reshape(-1,1)\n",
    "    this_pred = np.add(np.round(original_feature_set.values.dot(col_coefs),3), intercept)\n",
    "    return 1/(1 + np.exp(-this_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.218"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_dict = coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature_set['teste_feature'] = original_feature_set['DIS_9_bin_1'] | original_feature_set['DIS_9_bin_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coef_dict['teste_feature'] = 0.218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all['new_preds'] = make_preds(original_feature_set, new_coef_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.60009471884184"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.log_loss(y_all['bin_lstat'], y_all['new_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_lstat</th>\n",
       "      <th>new_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bin_lstat  new_preds\n",
       "0            0        0.0\n",
       "1            0        0.0\n",
       "2            0        0.0\n",
       "3            0        1.0\n",
       "4            0        0.0\n",
       "..         ...        ...\n",
       "501          0        1.0\n",
       "502          0        1.0\n",
       "503          0        1.0\n",
       "504          0        1.0\n",
       "505          0        0.0\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -18.59017554414894\n",
       " hess_inv: array([[1]])\n",
       "      jac: array([0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 9\n",
       "      nit: 1\n",
       "     njev: 3\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-5.05])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 5.552074997367714e-17\n",
       " hess_inv: array([[0.50000004]])\n",
       "      jac: array([-1.28826571e-12])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 21\n",
       "      nit: 4\n",
       "     njev: 7\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-7.45122473e-09])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(x, a,b,c):\n",
    "    return a*x**2 + b*x + c\n",
    "\n",
    "minimize(fun, 100, args=(1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -0.5860022592398136\n",
       " hess_inv: array([[1]])\n",
       "      jac: array([0.])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 3\n",
       "      nit: 0\n",
       "     njev: 1\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['teste'] = np.round(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5860022592398136"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(preds['bin_lstat'], preds['teste'], pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_lstat</th>\n",
       "      <th>preds</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bin_lstat  preds  residual\n",
       "169          1  1.000     0.000\n",
       "447          1  0.484     0.516\n",
       "490          1  1.000     0.000\n",
       "473          1  1.000     0.000\n",
       "438          1  1.000     0.000\n",
       "149          1  1.000     0.000\n",
       "165          0  1.000    -1.000\n",
       "496          1  1.000     0.000\n",
       "337          1  0.000     1.000\n",
       "227          0  1.000    -1.000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals.sort_values(['residual']).sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000    295\n",
       " 1.000    133\n",
       "-1.000     53\n",
       " 0.996      2\n",
       "-0.199      2\n",
       " 0.990      1\n",
       " 0.125      1\n",
       "-0.108      1\n",
       "-0.044      1\n",
       " 0.218      1\n",
       "-0.036      1\n",
       "-0.120      1\n",
       "-0.790      1\n",
       "-0.976      1\n",
       "-0.998      1\n",
       "-0.999      1\n",
       " 0.516      1\n",
       "-0.001      1\n",
       "-0.846      1\n",
       "-0.958      1\n",
       "-0.917      1\n",
       "-0.996      1\n",
       "-0.952      1\n",
       " 0.979      1\n",
       " 0.998      1\n",
       " 0.975      1\n",
       "Name: residual, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals['residual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1/ (1 * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
