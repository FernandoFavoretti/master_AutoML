{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(train_set: List[pd.DataFrame],\n",
    "                         test_set: List[pd.DataFrame],\n",
    "                         features: List[str],\n",
    "                         target: str,\n",
    "                         test_metrics: List[str],\n",
    "#                          validation_set: List[pd.DataFrame] = None,\n",
    "                         core_params: Dict[str, any] = {},\n",
    "                         hyper_params: Dict[str, any] = {},\n",
    "                         prediction_column: str = \"preds\",\n",
    "                         real_values_column: str = \"real_value\",\n",
    "                         log: bool = False,\n",
    "                         project_name: str = None\n",
    "                         ) -> Callable:    \n",
    "    \"\"\"\n",
    "    Fits a XGB regressor to the dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_set: List of pandas.DataFrame\n",
    "        [X_train, y_test]\n",
    "        A list of pandas Dataframe with features and target columns. \n",
    "        Already transformed.\n",
    "        The model will be trained to predict the target colum.\n",
    "        \n",
    "    test_set: List of pandas.DataFrame\n",
    "        [X_test, y_test]\n",
    "        A list of pandas Dataframe with features and target columns. \n",
    "        Already transformed.\n",
    "        The model will be trained to predict the target colum.\n",
    "\n",
    "    features: list of str\n",
    "        the list of features used to train the model\n",
    "        (used for feature importance and log)\n",
    "    \n",
    "    target: str\n",
    "        the target feature used in the model\n",
    "        (used for log only)\n",
    "        \n",
    "    test_metrics: list of str\n",
    "        list of measurement metrics to use, must be on\n",
    "        mae: mean absolute error\n",
    "        mdae: median absolute error\n",
    "        mse: mean squared error\n",
    "        rmse: root mean squared error\n",
    "        msle: mean squared log error\n",
    "        rmsle: root mean squared error\n",
    "        r2: r squared\n",
    "    \n",
    "    validation_set: list of [train_data, validation_data]\n",
    "        Lgbm validation set for earling stop\n",
    "        \n",
    "    core_params: dict, optional\n",
    "        core_params of the algorithm\n",
    "        defaults\n",
    "        ---------\n",
    "        num_boost_round, valid_sets=None, valid_names=None,\n",
    "        fobj=None, feval=None, init_model=None, feature_name='auto',\n",
    "        categorical_feature='auto', early_stopping_rounds=None,\n",
    "        evals_result=None, verbose_eval=True, learning_rates=None,\n",
    "        keep_training_booster=False, callbacks=None\n",
    "        ---------\n",
    "        \n",
    "    hyperparams: dict, optional\n",
    "        The params of the lgbm regression\n",
    "        dict in format of {'hyperparameter_name': hyperparameter_value}\n",
    "        If not passed the default will be used\n",
    "        \n",
    "    prediction_column: str\n",
    "        The name of the column with the predictions from the model\n",
    "        default `preds`\n",
    "        \n",
    "    real_value: str\n",
    "        The name of the column with the real value from test set\n",
    "        default `real_value`\n",
    "        \n",
    "    log: boll\n",
    "        Boolean condition if the model log should be generated into mlflow\n",
    "    \n",
    "    project_name: str\n",
    "        Name of the project for log, only used if log = True\n",
    " \n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    \n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "\n",
    "    start_fit = time.time()\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    end_fit = time.time()\n",
    "    \n",
    "    def predict(X_test: pd.DataFrame, y_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        col_dict = {prediction_column: model.predict_proba(X_test)[:,1],\n",
    "                    real_values_column: y_test}\n",
    "    \n",
    "        return X_test.assign(**col_dict)\n",
    "    \n",
    "    def measure_metric(df_with_preds, test_metrics):\n",
    "        dict_metrics = {}\n",
    "        # double checking for nan\n",
    "        df_with_preds[real_values_column] = df_with_preds[real_values_column].fillna(df_with_preds[real_values_column].mean())\n",
    "        df_with_preds[prediction_column] = df_with_preds[prediction_column].fillna(df_with_preds[prediction_column].mean())\n",
    "        for metric in test_metrics:\n",
    "            metric_func = getattr(classification_metrics, metric)\n",
    "            dict_metrics[metric] = metric_func(df_with_preds[real_values_column], df_with_preds[prediction_column])\n",
    "        return dict_metrics\n",
    "    \n",
    "    start_pred = time.time()\n",
    "    df_with_preds = predict(X_test, y_test)\n",
    "    end_pred = time.time()\n",
    "    dict_metrics = measure_metric(df_with_preds, test_metrics)\n",
    "    \n",
    "    dict_return = {'model_object': model,\n",
    "                   'pred_func': predict,\n",
    "                   'df_with_preds':df_with_preds,\n",
    "                   'calc_metrics': dict_metrics,\n",
    "                   'time_elapsed': {'fit': end_fit-start_fit, 'predict': end_pred - start_pred}\n",
    "                  }\n",
    "        \n",
    "    \n",
    "    return dict_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tree_regressors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2add1b2976b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtree_regressors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgb_regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# core_params = {}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tree_regressors'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "data = pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names\n",
    "data['PRICE'] = boston.target\n",
    "\n",
    "X, y = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "from tree_regressors import xgb_regressor\n",
    "\n",
    "# core_params = {}\n",
    "hyper_params = {'objective': 'reg:squarederror', 'colsample_bytree': 0.3, 'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10, 'n_estimators': 10}\n",
    "\n",
    "x = xgb_regressor(train_set = [X_train, y_train],\n",
    "     test_set = [X_test, y_test],\n",
    "     features = boston.feature_names,\n",
    "     target = 'PRICE',\n",
    "     test_metrics = ['rmse'],\n",
    "     validation_set = [X_test, y_test],\n",
    "     core_params= {},\n",
    "     hyper_params= hyper_params\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.037420501179529}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['calc_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
