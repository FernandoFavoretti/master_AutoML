{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fangorn.files_prep import get_data, data_to_pandas\n",
    "from fangorn.preprocessing import splitting, feature_selection\n",
    "from fangorn.training import classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml(model: str, train_dict: Dict[str, Any]) ->  Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run ml models returning the log dict of each one\n",
    "    \"\"\"\n",
    "    if model=='xgb':\n",
    "        resulted_classifier = classifiers.xgb_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "        \n",
    "    elif model == 'lgbm':\n",
    "        resulted_classifier = classifiers.lgbm_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "        \n",
    "    elif model == 'rf':\n",
    "        resulted_classifier = classifiers.random_forest_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "    elif model == 'logit':\n",
    "        resulted_classifier = classifiers.logistic_regression_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "    \n",
    "    return resulted_classifier\n",
    "\n",
    "def generate_report(dataset:str, model: str, train_dict: Dict[str, Any], resulted_classifier) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe for report\n",
    "    \"\"\"\n",
    "    df_report = pd.DataFrame()\n",
    "    df_report['dataset'] = [f'{dataset}']\n",
    "    df_report['model'] = f'{model}_baseline'\n",
    "    \n",
    "    df_report['train_shape_rows'] = [train_dict['train']['X'].shape[0]]\n",
    "    df_report['train_shape_cols'] = [train_dict['train']['X'].shape[1]]\n",
    "    df_report['fit_time'] = float('%.3f' % resulted_classifier['time_elapsed']['fit'])\n",
    "    \n",
    "    df_report['test_shape_rows'] = [train_dict['test']['X'].shape[0]]\n",
    "    df_report['test_shape_cols'] = [train_dict['train']['X'].shape[1]]\n",
    "    df_report['predict_time'] = float('%.3f' % resulted_classifier['time_elapsed']['predict'])\n",
    "    \n",
    "    # metrics report\n",
    "    for key,value in resulted_classifier['calc_metrics'].items():\n",
    "        df_report[key] = value \n",
    "\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML_CHALLENGE files ready!\n",
      "working in christine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "\t working in logit\n"
     ]
    }
   ],
   "source": [
    "def run_holdout_baseline():\n",
    "    all_datasets = get_data.get_all_data(only='ml_challenge')\n",
    "    all_models = ['xgb', 'lgbm', 'rf', 'logit']\n",
    "    baseline_df = pd.DataFrame()\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        print(f\"working in {dataset}\")\n",
    "        X_all, y_all = data_to_pandas.read_prepare_data(dataset)\n",
    "        train_dict = splitting.simple_train_test_val_split(X_all, y_all)\n",
    "        for model in all_models:\n",
    "            print(f\"\\t working in {model}\")\n",
    "            resulted_classifier = run_ml(model, train_dict)\n",
    "            # creating a dataframe with results\n",
    "            df_tmp = generate_report(dataset, model, train_dict, resulted_classifier)\n",
    "            baseline_df = baseline_df.append(df_tmp)\n",
    "    return baseline_df\n",
    "\n",
    "run_holdout_baseline().to_excel('baseline_classifier.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold_baseline(select_features: bool = False):\n",
    "    all_datasets = get_data.get_all_data(only='ml_challenge')\n",
    "    all_models = ['xgb', 'lgbm', 'rf']\n",
    "    baseline_df = pd.DataFrame()\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        print(f\"working in {dataset}\")\n",
    "        X_all, y_all = data_to_pandas.read_prepare_data(dataset)\n",
    "        if select_features:\n",
    "            print(\"Simple feature selection\")\n",
    "            X_all_old_shape = X_all.shape[1]\n",
    "            X_all = feature_selection.extra_trees_feature_selection(X_all, y_all)\n",
    "            print(f\"Feature space (old x new): {X_all_old_shape} x {X_all.shape[1]}\")\n",
    "        all_folds = splitting.stratified_kfold_train_test_split(X_all, y_all)\n",
    "        for model in all_models:\n",
    "            print(f\"\\t working in {model}\")\n",
    "            fold_results = []\n",
    "            for fold in all_folds:\n",
    "                # para cada fold, treina, e gera um report\n",
    "                tmp_resulted_classifier = run_ml(model, fold)\n",
    "                fold_results.append(generate_report(dataset, model, fold, tmp_resulted_classifier))\n",
    "            # tira a media dos resultados dos folds e agrupa no df baseline final\n",
    "            df_tmp = pd.concat(fold_results).groupby(['dataset', 'model'], as_index=False).mean()\n",
    "            baseline_df = baseline_df.append(df_tmp)\n",
    "\n",
    "    return baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML_CHALLENGE files ready!\n",
      "working in christine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in jasmine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in philippine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in madeline\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in sylvine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n"
     ]
    }
   ],
   "source": [
    "run_kfold_baseline(select_features=False).to_excel('baselin'e_classifier_kfold_.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ML_CHALLENGE files ready!\n",
      "working in christine\n",
      "Simple feature selection\n",
      "Feature space (old x new): 1636 x 462\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in jasmine\n",
      "Simple feature selection\n",
      "Feature space (old x new): 144 x 50\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in philippine\n",
      "Simple feature selection\n",
      "Feature space (old x new): 308 x 68\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in madeline\n",
      "Simple feature selection\n",
      "Feature space (old x new): 259 x 32\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in sylvine\n",
      "Simple feature selection\n",
      "Feature space (old x new): 20 x 3\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n"
     ]
    }
   ],
   "source": [
    "run_kfold_baseline(select_features=True).to_excel('baseline_classifier_kfold_SIMPLE_ET_FS.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
