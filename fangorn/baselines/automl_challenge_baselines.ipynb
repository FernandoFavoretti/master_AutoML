{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fangorn.files_prep import get_data, data_to_pandas\n",
    "from fangorn.preprocessing import splitting\n",
    "from fangorn.training import classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ml(model: str, train_dict: Dict[str, Any]) ->  Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run ml models returning the log dict of each one\n",
    "    \"\"\"\n",
    "    if model=='xgb':\n",
    "        resulted_classifier = classifiers.xgb_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "        \n",
    "    elif model == 'lgbm':\n",
    "        resulted_classifier = classifiers.lgbm_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "        \n",
    "    elif model == 'rf':\n",
    "        resulted_classifier = classifiers.random_forest_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "    elif model == 'logit':\n",
    "        resulted_classifier = classifiers.logistic_regression_classifier(\n",
    "                train_set = [train_dict['train']['X'], train_dict['train']['y']],\n",
    "                test_set = [train_dict['test']['X'], train_dict['test']['y']],\n",
    "                features = train_dict['test']['X'].columns,\n",
    "                target = train_dict['test']['y'].columns[0],\n",
    "                test_metrics = ['acc', 'precision', 'recall', 'f1','auc']\n",
    "            )\n",
    "    \n",
    "    return resulted_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(dataset:str, model: str, train_dict: Dict[str, Any], resulted_classifier) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a dataframe for report\n",
    "    \"\"\"\n",
    "    df_report = pd.DataFrame()\n",
    "    df_report['dataset'] = [f'{dataset}']\n",
    "    df_report['model'] = f'{model}_baseline'\n",
    "    \n",
    "    df_report['train_shape'] = [train_dict['train']['X'].shape]\n",
    "    df_report['fit_time'] = '%.3f' % resulted_classifier['time_elapsed']['fit']\n",
    "    \n",
    "    df_report['test_shape'] = [train_dict['test']['X'].shape]\n",
    "    df_report['predict_time'] = '%.3f' % resulted_classifier['time_elapsed']['predict']\n",
    "    \n",
    "    # metrics report\n",
    "    for key,value in resulted_classifier['calc_metrics'].items():\n",
    "        df_report[key] = value \n",
    "\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='christine'\n",
    "model = 'logit'\n",
    "X_all, y_all = data_to_pandas.read_prepare_data(dataset)\n",
    "train_dict = splitting.simple_train_test_val_split(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/favoretti/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "resulted_classifier = run_ml(model, train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6171586715867159,\n",
       " 'precision': 0.617022073341776,\n",
       " 'recall': 0.6171916283414529,\n",
       " 'f1': 0.6081208687440982,\n",
       " 'auc': 0.6671382741892045}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulted_classifier['calc_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<configparser.ConfigParser object at 0x7f234a615710>\n",
      "All ML_CHALLENGE files ready!\n",
      "working in christine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in jasmine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in philippine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in madeline\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n",
      "working in sylvine\n",
      "\t working in xgb\n",
      "\t working in lgbm\n",
      "\t working in rf\n"
     ]
    }
   ],
   "source": [
    "all_datasets = get_data.get_all_data(only='ml_challenge')\n",
    "all_models = ['xgb', 'lgbm', 'rf']\n",
    "baseline_df = pd.DataFrame()\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    print(f\"working in {dataset}\")\n",
    "    X_all, y_all = data_to_pandas.read_prepare_data(dataset)\n",
    "    train_dict = splitting.simple_train_test_val_split(X_all, y_all)\n",
    "    for model in all_models:\n",
    "        print(f\"\\t working in {model}\")\n",
    "        resulted_classifier = run_ml(model, train_dict)\n",
    "        # creating a dataframe with results\n",
    "        df_tmp = generate_report(dataset, model, train_dict, resulted_classifier)\n",
    "        baseline_df = baseline_df.append(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.to_excel('baseline_classifier.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
